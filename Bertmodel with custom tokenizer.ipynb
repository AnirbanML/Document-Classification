{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05d2e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertModel\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0fe4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 3000\n",
    "pd.options.display.max_rows = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c776098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c436419b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314492, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23012/3006793153.py:4: DtypeWarning: Columns (6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data=pd.read_csv('./master_data_V3_0.csv')\n"
     ]
    }
   ],
   "source": [
    "#data = pd.read_csv('./Backup master data/master_data_6.csv', usecols=['ADR', 'text', 'category', 'type', 'date'])\n",
    "# old_data = pd.read_csv('./oldnew.csv')\n",
    "# data = pd.read_csv('./master_data_new.csv')\n",
    "data=pd.read_csv('./master_data_V3_0.csv')\n",
    "# print(old_data.shape)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc300f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91942ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ADR', 'text', 'category', 'type', 'date', 'ogr/aug', 'page#', 'angle',\n",
       "       'renamed category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de5ac351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "961e8e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LD      280866\n",
       "NMIC     33626\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "403f146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_data_cat=old_data['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bff03af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data_cat=data['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "388c1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_in_newdata=set()\n",
    "# for cat in old_data_cat:\n",
    "#     if cat not in new_data_cat:\n",
    "#         not_in_newdata.add(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02ff5113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_data_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1368c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6542d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_data[(old_data['category']=='NotClassified')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0efe77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dd in not_in_newdata:\n",
    "#     print(dd)\n",
    "# #     print(old_data[old_data['category']==dd]['org/aug'].value_counts())\n",
    "#     tdf=pd.DataFrame(old_data[(old_data['category']==dd) & (old_data['org/aug']=='org')])\n",
    "#     print(tdf.shape[0])\n",
    "#     tdf['page#']=[-1]*tdf.shape[0]\n",
    "#     tdf['angle']=[0]*tdf.shape[0]\n",
    "# #     break\n",
    "#     data=data.append(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b55b6909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADR                     0\n",
       "text                 1649\n",
       "category                0\n",
       "type                    0\n",
       "date                    0\n",
       "ogr/aug                 0\n",
       "page#                   0\n",
       "angle                  17\n",
       "renamed category    84347\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19d4f28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229177, 9)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2bd647dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tax Return - Personal                                 98667\n",
       "Bank Statement                                        31728\n",
       "Tax Return - Business                                 20913\n",
       "Retirement Account Statement(s)                        9797\n",
       "Paystub                                                8463\n",
       "Hazard Insurance Dec Page - Initial                    8187\n",
       "W-2(s) / 1099(s)                                       6617\n",
       "Condominium Documents                                  6348\n",
       "Rental Agreements(s)                                   5778\n",
       "Mortgage Statement                                     5735\n",
       "Purchase Agreement                                     4763\n",
       "Divorce Decree / Child Support                         3619\n",
       "Divorce Decree                                         3220\n",
       "Title Report                                           3175\n",
       "Escrow/Closing Instructions                            1995\n",
       "K1s                                                    1389\n",
       "Driver's License                                       1218\n",
       "Letter of Explanation                                   989\n",
       "Bankruptcy Papers                                       968\n",
       "Award Letter(s)                                         894\n",
       "NOTE with all Attachments                               859\n",
       "Setup Submission Form                                   562\n",
       "Social Security Award Letter                            494\n",
       "Credit Report                                           473\n",
       "Escrow / Closing Instructions                           389\n",
       "Trust Certification                                     380\n",
       "Disclosures                                             333\n",
       "SSN Card                                                247\n",
       "Non-Mortgage Account Statement                          216\n",
       "IRS Transcripts                                         119\n",
       "VA - DD214 Member Copy for Discharge                     98\n",
       "1003                                                     84\n",
       "Due Diligence Report                                     62\n",
       "Tax Returns                                              60\n",
       "Permanent Resident Card                                  60\n",
       "Income - Other                                           55\n",
       "Others                                                   43\n",
       "Lender Approval                                          38\n",
       "4506-C                                                   37\n",
       "Flood Certificate                                        20\n",
       "Appraisal - Appraisal Report                             18\n",
       "Other                                                    18\n",
       "4506-T                                                   13\n",
       "W-9                                                      12\n",
       "Identification                                            5\n",
       "Condo/Coop/HOA                                            3\n",
       "DU Findings                                               3\n",
       "Verification of business (VOB)/SOS Business Search        3\n",
       "Property - Other                                          2\n",
       "Title - Other                                             2\n",
       "Profit & Loss(s)                                          1\n",
       "Business License                                          1\n",
       "Appraisal – Other                                         1\n",
       "Closing Disclosure                                        1\n",
       "LP Findings                                               1\n",
       "Gift Letter                                               1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2685d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data[data['category']=='Tax Return - Personal'].index.tolist()\n",
    "data.drop(index= random.sample(n, 60000), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe4595d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tax Return - Personal                                 38667\n",
       "Bank Statement                                        31728\n",
       "Tax Return - Business                                 20913\n",
       "Retirement Account Statement(s)                        9797\n",
       "Paystub                                                8463\n",
       "Hazard Insurance Dec Page - Initial                    8187\n",
       "W-2(s) / 1099(s)                                       6617\n",
       "Condominium Documents                                  6348\n",
       "Rental Agreements(s)                                   5778\n",
       "Mortgage Statement                                     5735\n",
       "Purchase Agreement                                     4763\n",
       "Divorce Decree / Child Support                         3619\n",
       "Divorce Decree                                         3220\n",
       "Title Report                                           3175\n",
       "Escrow/Closing Instructions                            1995\n",
       "K1s                                                    1389\n",
       "Driver's License                                       1218\n",
       "Letter of Explanation                                   989\n",
       "Bankruptcy Papers                                       968\n",
       "Award Letter(s)                                         894\n",
       "NOTE with all Attachments                               859\n",
       "Setup Submission Form                                   562\n",
       "Social Security Award Letter                            494\n",
       "Credit Report                                           473\n",
       "Escrow / Closing Instructions                           389\n",
       "Trust Certification                                     380\n",
       "Disclosures                                             333\n",
       "SSN Card                                                247\n",
       "Non-Mortgage Account Statement                          216\n",
       "IRS Transcripts                                         119\n",
       "VA - DD214 Member Copy for Discharge                     98\n",
       "1003                                                     84\n",
       "Due Diligence Report                                     62\n",
       "Tax Returns                                              60\n",
       "Permanent Resident Card                                  60\n",
       "Income - Other                                           55\n",
       "Others                                                   43\n",
       "Lender Approval                                          38\n",
       "4506-C                                                   37\n",
       "Flood Certificate                                        20\n",
       "Appraisal - Appraisal Report                             18\n",
       "Other                                                    18\n",
       "4506-T                                                   13\n",
       "W-9                                                      12\n",
       "Identification                                            5\n",
       "Condo/Coop/HOA                                            3\n",
       "DU Findings                                               3\n",
       "Verification of business (VOB)/SOS Business Search        3\n",
       "Property - Other                                          2\n",
       "Title - Other                                             2\n",
       "Profit & Loss(s)                                          1\n",
       "Business License                                          1\n",
       "Appraisal – Other                                         1\n",
       "Closing Disclosure                                        1\n",
       "LP Findings                                               1\n",
       "Gift Letter                                               1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4af34be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for category in data['category']:\n",
    "    if category == 'Divorce Decree':\n",
    "        temp.append('Divorce Decree / Child Support')\n",
    "    elif category == 'Escrow / Closing Instructions':\n",
    "        temp.append('Escrow/Closing Instructions')\n",
    "    else:\n",
    "#         temp.append('focused')\n",
    "        temp.append(category)\n",
    "data['category'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b4ff81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['org/aug'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef3f45",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "85f68831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Setup Submission Form', 'VA - DD214 Member Copy for Discharge',\n",
       "       'Bank Statement', 'Retirement Account Statement(s)', 'SSN Card',\n",
       "       'Divorce Decree / Child Support', 'Social Security Award Letter',\n",
       "       'Award Letter(s)', 'Tax Return - Business', 'Flood Certificate',\n",
       "       'Paystub', 'Hazard Insurance Dec Page - Initial', 'K1s',\n",
       "       'Tax Return - Personal', 'Mortgage Statement', \"Driver's License\",\n",
       "       'Permanent Resident Card', 'W-2(s) / 1099(s)',\n",
       "       'Purchase Agreement', 'Rental Agreements(s)',\n",
       "       'Escrow/Closing Instructions', 'Trust Certification',\n",
       "       'Bankruptcy Papers', 'Condominium Documents',\n",
       "       'NOTE with all Attachments', 'Title Report',\n",
       "       'Letter of Explanation', 'Non-Mortgage Account Statement',\n",
       "       'Lender Approval', 'Disclosures', 'Credit Report', '4506-C',\n",
       "       'Title - Other', 'IRS Transcripts', 'Income - Other',\n",
       "       'Property - Other', 'W-9', 'Others', '4506-T', '1003',\n",
       "       'Verification of business (VOB)/SOS Business Search',\n",
       "       'Tax Returns', 'Business License', 'Due Diligence Report',\n",
       "       'Profit & Loss(s)', 'Other', 'DU Findings', 'Condo/Coop/HOA',\n",
       "       'Appraisal – Other', 'Closing Disclosure', 'Identification',\n",
       "       'Appraisal - Appraisal Report', 'LP Findings', 'Gift Letter'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2133e6f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADR</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>ogr/aug</th>\n",
       "      <th>page#</th>\n",
       "      <th>angle</th>\n",
       "      <th>renamed category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111629</th>\n",
       "      <td>ADR-2022-200000370062</td>\n",
       "      <td>AMERICAN Platinum Card® p. 1/12 EXPRESS JAMES C RAWSON Customer Care: 1-800-525-3355 ITY: Closing Date 04/13/22 Use Relay 711 Account Ending 5-82006 Website: americanexpress.com Membership Rewards® Points New Balance $5,365.93 Available and Pending as of 03/31/22 Minimum Payment Due $2,721.72 688 For up to date point balance and full program details, visit membershiprewards.com Payment Due Date 05/08/22 Account Summary Pay In Full Late Payment Warning: If we do not receive your Minimum Payment Due by the Payment Due Date of 05/08/22, you may have to pay a late fee of up to Previous Balance $1,686.37 $40.00 and your Pay Over Time APR may be increased to the Penalty APR of Payments/Credits $1,741.82 29.99%. New Charges +$2,723.21 Fees +$0.00 New Balance $2,667.76 Pay Over Time and/or Cash Advance Previous Balance $5,441.91 Minimum Payment Warning: If you have a Pay Over Time and/or Cash Advance Payments/Credits -$12,841.21 balance and you make only the minimum payment each period, you will pay more in New Pay Over Time Charges +$9,203.85 interest and it will take you longer to pay off your balance. For example: New Cash Advances +$0.00 If you make no additional You will pay off the balance And you will pay an Fees +$870.00 charges and each month shown on this statement in estimated total of ... Interest Charged +$23.62 New Balance $2,698.17 you pay .. about ... Minimum Due $53.96 Only the Account Total 10 years $5,478 Minimum Payment Due Previous Balance $7,128.28 Payments/Credits -$14,583.03 If you would like information about credit counseling services, call 1-888-733-4139. New Charges +$11,927.06 See page 2 for important information about your account. New Cash Advances +$0.00 Fees +$870.00 Please refer to the IMPORTANT NOTICES section on Interest Charged +$23.62 pages 11 - 12. New Balance $5,365.93 Minimum Payment Due $2,721.72 We will debit your bank account for your payment of $2,721.72 on 04/28/22. This date may not be the same date your bank will debit your Pay Over Time Limit $22,500.00 bank account. Any inquiry to American Express concerning this debit Available Pay Over Time Limit $19,801.83 should be made before 04/26/22. If your AutoPay payment is less than your Minimum Payment Due, we must receive an additional payment for at least the difference by 05/08/22. Continued on page 3 Payment Coupon Pay by Computer Pay by Phone Account Ending 5-82006 Do not staple or use paper clips americanexpress.com/pbc 1-800-472-9297 Enter 15 digit account # on all payments. Make check payable to American Express. JAMES C RAWSON Payment Due Date 30 SANTA ANA LOOP 05/08/22 PLACITAS NM 87043-9440 New Balance $5,365.93 AutoPay Amount $2,721.72 See reverse side for instructions AMERICAN EXPRESS S P.O. BOX 650448 on how to update your address, DALLAS TX 75265-0448 Amount Enclosed phone number, or email. 0000349992556891747 000536593000272172 10</td>\n",
       "      <td>Non-Mortgage Account Statement</td>\n",
       "      <td>NMIC</td>\n",
       "      <td>20220722194403</td>\n",
       "      <td>org</td>\n",
       "      <td>509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111630</th>\n",
       "      <td>ADR-2022-200000370062</td>\n",
       "      <td>JAMES C RAWSON Account Ending 5-82006 p. 2/12 Payments: Your payment must be sent to the payment address shown on effect on the date of your charge. Charges converted by establishments will your statement and must be received by 5 p.m. local time at that address to be billed at the rates such establishments use. be credited as of the day it is received. Payments we receive after 5 p.m. will Credit Balance: A credit balance (designated CR) shown on this statement not be credited to your Account until the next day. Payments must also: (1) represents money owed to you. If within the six-month period following include the remittance coupon from your statement; (2) be made with a the date of the first statement indicating the credit balance you do not single check drawn on a US bank and payable in US dollars, or with a request a refund or charge enough to use up the credit balance, we will negotiable instrument payable in US dollars and clearable through the US send you a check for the credit balance within 30 days if the amount is banking system; and (3) include your Account number. If your payment $1.00 or more. does not meet all of the above requirements, crediting may be delayed and Credit Reporting: We may report information about your Account to credit you may incur late payment fees and additional interest charges. Electronic bureaus. Late payments, missed payments, or other defaults on your payments must be made through an electronic payment method payable Account may be reflected in your credit report. in US dollars and clearable through the US banking system. Please do not What To Do If You Think You Find A Mistake On Your Statement send post-dated checks as they will be deposited upon receipt. Any If you think there is an error on your statement, write to us at: restrictive language on a payment we accept will have no effect on us American Express, PO Box 981535, El Paso TX 79998-1535 without our express prior written approval. We will re-present to your You may also contact us on the Web: www.americanexpress.com financial institution any payment that is returned unpaid. If you have a Pay In your letter, give us the following information: Over Time balance, you may pay more than the Minimum Payment Due, up - Account information: Your name and account number. to your New Balance, at any time. - Dollar amount: The dollar amount of the suspected error. Permission for Electronic Withdrawal: (1) When you send a check for - Description of Problem: If you think there is an error on your bill, describe what you believe is wrong and why you believe it is a mistake. payment, you give us permission to electronically withdraw your payment from your deposit or other asset account. We will process checks You must contact us within 60 days after the error appeared on your electronically by transmitting the amount of the check, routing number, statement. account number and check serial number to your financial institution, You must notify us of any po...</td>\n",
       "      <td>Non-Mortgage Account Statement</td>\n",
       "      <td>NMIC</td>\n",
       "      <td>20220722194403</td>\n",
       "      <td>org</td>\n",
       "      <td>510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111631</th>\n",
       "      <td>ADR-2022-200000370062</td>\n",
       "      <td>AMERICAN Platinum Card® p. 3/12 EXPRESS JAMES C RAWSON Closing Date 04/13/22 Account Ending 5-82006 Customer Care &amp; Billing Inquiries 1-800-525-3355 International Collect 1-954-473-2123 Website: americanexpress.com Cash Advance at ATMs Inquiries 1-800-CASH-NOW Large Print &amp; Braille Statements 1-800-525-3355 Customer Care &amp; Billing Inquiries Payments P.O. BOX 981535 P.O. BOX 650448 EL PASO, TX DALLAS TX 75265- Hearing Impaired 79998-1535 0448 Online chat at americanexpress.com or use Relay dial 711 and 1-800-525-3355 For more information on your Pay Over Time Limit and your purchasing options, please see page 10 Reminder about changes to Pay Over Time As a reminder, we're making a change to Pay Over Time as of May 1, 2022, that will allow you to choose to carry a balance with interest on additional charges that were previously below the eligible amount. This will give you more payment flexibility with your everyday purchases. For further details, please refer to the notification that was sent to you in February 2022. If you have rejected this change to Pay Over Time (or do so by April 30, 2022), the minimum dollar amount for eligible Pay Over Time charges on your account will not change. If you have any questions, please call the Customer Care number on your billing statement. O, Congratulations! You saved with offers and benefits this statement period. Please refer to the Payments and Credits section of your statement. View all available offers and benefits when you log in to your online Card account at americanexpress.com Find local spots near you LET'S GRAB A TABLE. LET'S GO SHOP SMALL. By eating local, you support the small businesses at the heart of your community. Visit ShopSmall.com to learn more. Scan code with your smartphone camera Payments and Credits Summary Pay Over Time / Pay In Full Cash Advance + Tota Payments -$1,686.37 -$10,114.87 -$11,801.24 Credits JAMES C RAWSON 5-82006 -$55.45 -$2,726.34 -$2,781.79 Total Payments and Credits -$1,741.82 -$12,841.21 -$14,583.03 Detail *Indicates posting date - denotes Pay Over Time and/or Cash Advance activity Payments Amount 03/15/22* JAMES C RAWSON ONLINE PAYMENT - THANK YOU $3,000.00 03/25/22* JAMES C RAWSON ONLINE PAYMENT - THANK YOU $2,500.00 03/31/22* JAMES C RAWSON ONLINE PAYMENT - THANK YOU -$6,301.24 Credits Amount Continued on reverse</td>\n",
       "      <td>Non-Mortgage Account Statement</td>\n",
       "      <td>NMIC</td>\n",
       "      <td>20220722194403</td>\n",
       "      <td>org</td>\n",
       "      <td>511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111632</th>\n",
       "      <td>ADR-2022-200000370062</td>\n",
       "      <td>JAMES C RAWSON Account Ending 5-82006 p. 4/12 Detail Continued *Indicates posting date - denotes Pay Over Time and/or Cash Advance activity Amount 03/26/22 JAMES C RAWSON UNITED AIRLINES -$207.00* TX HOUSTON UNITED AIRLINES From: To: Carrier: Class: CHICAGO O'HARE INT CHICAGO O'HARE INT UA 00 Ticket Number: 01699804726480 Date of Departure: 03/26 Passenger Name: RAWSON /OTHER Document Type: SUPPORTED REFUND 03/26/22 JAMES C RAWSON UNITED AIRLINES -$49.00 HOUSTON TX UNITED AIRLINES From: To: Carrier: Class: CHICAGO O'HARE INT CHICAGO O'HARE INT UA 00 Ticket Number: 01699804726491 Date of Departure: 03/26 Passenger Name: RAWSON /OTHER Document Type: SUPPORTED REFUND 03/26/22 JAMES C RAWSON UNITED AIRLINES -$240.00 * HOUSTON TX UNITED AIRLINES From: To: Carrier: Class CHICAGO O'HARE INT CHICAGO O'HARE INT UA 00 Ticket Number: 01699804728952 Date of Departure: 03/26 Passenger Name: RAWSON /OTHER Document Type: SUPPORTED REFUND 03/28/22 JAMES C RAWSON UNITED AIRLINES -$1,039.67 + HOUSTON TX UNITED AIRLINES From: To: Carrier: Class DENPASAR BALI SINGAPORE CHANGI A SQ 00 SAN FRANCISCO INTL UA 00 DENVER INTL APT UA 00 ALBUQUERQUE UA Ticket Number: 01624025800374 00 Date of Departure: 06/14 Passenger Name: RAWSON/JAMES Document Type: SUPPORTED REFUND 03/28/22 JAMES C RAWSON UNITED AIRLINES -$1,039.67 * HOUSTON TX UNITED AIRLINES From: To: Carrier: Class: DENPASAR BALI SINGAPORE CHANGI A SO 00 SAN FRANCISCO INTL UA 00 DENVER INTL APT UA 00 ALBUQUERQUE UA 00 Ticket Number: 01624025802765 Date of Departure: 06/14 Passenger Name: RAWSON/JAMES Document Type: SUPPORTED REFUND 03/29/22* JAMES C RAWSON AMEX Airline Fee Reimbursement -$200.00 * TRANSACTION PROCESSED BY AMERICAN EXPRESS 04/07/22 JAMES C RAWSON SIRIUS RADIO INC -$6.45 NEW YORK Amex Digital Ent New Charges Summary Pay In Full Pay Over Time + Tota JAMES C RAWSON 5-82006 $2,083.66 $8,526.97 $10,610.63 AUDREY MAE N RAWSON 5-82014 $639.55 $676.88 $1,316.43 Total New Charges $2,723.21 $9,203.85 $11,927.06 Continued on next page</td>\n",
       "      <td>Non-Mortgage Account Statement</td>\n",
       "      <td>NMIC</td>\n",
       "      <td>20220722194403</td>\n",
       "      <td>org</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111633</th>\n",
       "      <td>ADR-2022-200000370062</td>\n",
       "      <td>AMERICAN Platinum Card® p. 5/12 EXPRESS JAMES C RAWSON Closing Date 04/13/22 Account Ending 5-82006 Detail + - denote: Pay Over Time and/or Cash Advance activity JAMES C RAWSON Card Ending 5-82006 Foreign Spend Amount GOOGLE*YOUTUBEPREMIUM GOOGLE PAYMENT G.CO HELPPAY# 03/14/22 $12.55 CABLE &amp; PAY TV GOOGLE*YOUTUBE SUPER GOOGLE PAYMENT 03/15/22 G.CO HELPPAY# $2.09 VIDEO PRODUCTION 03/16/22 TACO BELL 05262 0526 BERNALILLO NM $7.03 505-867-0747 03/16/22 TESLA PALO ALTO $250.00 * AUTO SERVICE 03/17/22 PF CHANG'S ALBUQUERQUE NM $46.02 8464780747816965 871070 FOOD/BEVERAGE 03/19/22 S-A BBQ TIN CAN ALLEY Albuquerque NM $37.21 squareup.com/receipts TIN CAN ALLEY 156176060886851 ALBUQUERQUE NM 03/19/22 $47.00 BREWMAIN@PROCESSLOCAL.COM 03/19/22 SMITHS FOOD #4459 000004459 ALBUQUERQUE NM $63.11 8666111979 GROCERY STORES 03/19/22 TONAL SYSTEMS, INC SAN FRANCISCO CA $49.00 +18556986625 03/23/22 TACO BELL 05262 0526 BERNALILLO NM $7.03 505-867-0747 03/23/22 AMAZON MUSIC*1N1C50250 888-802-3080 WA $4.30 DIGITAL 03/23/22 AMAZON.COM*1N6021UM0 AMZN.COM/BILL WA $23.74 MERCHANDISE AMZN.COM/BILL 03/23/22 AMAZON.COM*1N9U078X2 WA $23.74 MERCHANDISE 03/25/22 UNITED AIRLINES HOUSTON TX $240.00 * UNITED AIRLINES From: Carrier: Class: SINGAPORE CHANGI A SAN FRANCISCO INTL UA 00 Ticket Number: 01699804728952 Date of Departure: 06/15 Passenger Name: RAWSON /ECONOMY PLUS S Document Type: PREFERRED SEAT UPGRADE 03/25/22 UNITED AIRLINES HOUSTON TX $207.00 * UNITED AIRLINES From: To: Carrier: Class SINGAPORE CHANGI A SAN FRANCISCO INTL 00 Ticket Number: 01699804726480 Date of Departure: 06/15 Passenger Name: RAWSON /ECONOMY PLUS S Document Type: PREFERRED SEAT UPGRADE 03/25/22 UNITED AIRLINES HOUSTON TX $49.00 UNITED AIRLINES From: To: Carrier: Class DENVER INTL APT ALBUQUERQUE UA 00 Ticket Number: 01699804726491 Date of Departure: 06/15 Passenger Name: RAWSON /ECONOMY PLUS S Document Type: PREFERRED SEAT UPGRADE Continued on reverse</td>\n",
       "      <td>Non-Mortgage Account Statement</td>\n",
       "      <td>NMIC</td>\n",
       "      <td>20220722194403</td>\n",
       "      <td>org</td>\n",
       "      <td>513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ADR  \\\n",
       "111629  ADR-2022-200000370062   \n",
       "111630  ADR-2022-200000370062   \n",
       "111631  ADR-2022-200000370062   \n",
       "111632  ADR-2022-200000370062   \n",
       "111633  ADR-2022-200000370062   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text  \\\n",
       "111629                                                                                                                     AMERICAN Platinum Card® p. 1/12 EXPRESS JAMES C RAWSON Customer Care: 1-800-525-3355 ITY: Closing Date 04/13/22 Use Relay 711 Account Ending 5-82006 Website: americanexpress.com Membership Rewards® Points New Balance $5,365.93 Available and Pending as of 03/31/22 Minimum Payment Due $2,721.72 688 For up to date point balance and full program details, visit membershiprewards.com Payment Due Date 05/08/22 Account Summary Pay In Full Late Payment Warning: If we do not receive your Minimum Payment Due by the Payment Due Date of 05/08/22, you may have to pay a late fee of up to Previous Balance $1,686.37 $40.00 and your Pay Over Time APR may be increased to the Penalty APR of Payments/Credits $1,741.82 29.99%. New Charges +$2,723.21 Fees +$0.00 New Balance $2,667.76 Pay Over Time and/or Cash Advance Previous Balance $5,441.91 Minimum Payment Warning: If you have a Pay Over Time and/or Cash Advance Payments/Credits -$12,841.21 balance and you make only the minimum payment each period, you will pay more in New Pay Over Time Charges +$9,203.85 interest and it will take you longer to pay off your balance. For example: New Cash Advances +$0.00 If you make no additional You will pay off the balance And you will pay an Fees +$870.00 charges and each month shown on this statement in estimated total of ... Interest Charged +$23.62 New Balance $2,698.17 you pay .. about ... Minimum Due $53.96 Only the Account Total 10 years $5,478 Minimum Payment Due Previous Balance $7,128.28 Payments/Credits -$14,583.03 If you would like information about credit counseling services, call 1-888-733-4139. New Charges +$11,927.06 See page 2 for important information about your account. New Cash Advances +$0.00 Fees +$870.00 Please refer to the IMPORTANT NOTICES section on Interest Charged +$23.62 pages 11 - 12. New Balance $5,365.93 Minimum Payment Due $2,721.72 We will debit your bank account for your payment of $2,721.72 on 04/28/22. This date may not be the same date your bank will debit your Pay Over Time Limit $22,500.00 bank account. Any inquiry to American Express concerning this debit Available Pay Over Time Limit $19,801.83 should be made before 04/26/22. If your AutoPay payment is less than your Minimum Payment Due, we must receive an additional payment for at least the difference by 05/08/22. Continued on page 3 Payment Coupon Pay by Computer Pay by Phone Account Ending 5-82006 Do not staple or use paper clips americanexpress.com/pbc 1-800-472-9297 Enter 15 digit account # on all payments. Make check payable to American Express. JAMES C RAWSON Payment Due Date 30 SANTA ANA LOOP 05/08/22 PLACITAS NM 87043-9440 New Balance $5,365.93 AutoPay Amount $2,721.72 See reverse side for instructions AMERICAN EXPRESS S P.O. BOX 650448 on how to update your address, DALLAS TX 75265-0448 Amount Enclosed phone number, or email. 0000349992556891747 000536593000272172 10   \n",
       "111630   JAMES C RAWSON Account Ending 5-82006 p. 2/12 Payments: Your payment must be sent to the payment address shown on effect on the date of your charge. Charges converted by establishments will your statement and must be received by 5 p.m. local time at that address to be billed at the rates such establishments use. be credited as of the day it is received. Payments we receive after 5 p.m. will Credit Balance: A credit balance (designated CR) shown on this statement not be credited to your Account until the next day. Payments must also: (1) represents money owed to you. If within the six-month period following include the remittance coupon from your statement; (2) be made with a the date of the first statement indicating the credit balance you do not single check drawn on a US bank and payable in US dollars, or with a request a refund or charge enough to use up the credit balance, we will negotiable instrument payable in US dollars and clearable through the US send you a check for the credit balance within 30 days if the amount is banking system; and (3) include your Account number. If your payment $1.00 or more. does not meet all of the above requirements, crediting may be delayed and Credit Reporting: We may report information about your Account to credit you may incur late payment fees and additional interest charges. Electronic bureaus. Late payments, missed payments, or other defaults on your payments must be made through an electronic payment method payable Account may be reflected in your credit report. in US dollars and clearable through the US banking system. Please do not What To Do If You Think You Find A Mistake On Your Statement send post-dated checks as they will be deposited upon receipt. Any If you think there is an error on your statement, write to us at: restrictive language on a payment we accept will have no effect on us American Express, PO Box 981535, El Paso TX 79998-1535 without our express prior written approval. We will re-present to your You may also contact us on the Web: www.americanexpress.com financial institution any payment that is returned unpaid. If you have a Pay In your letter, give us the following information: Over Time balance, you may pay more than the Minimum Payment Due, up - Account information: Your name and account number. to your New Balance, at any time. - Dollar amount: The dollar amount of the suspected error. Permission for Electronic Withdrawal: (1) When you send a check for - Description of Problem: If you think there is an error on your bill, describe what you believe is wrong and why you believe it is a mistake. payment, you give us permission to electronically withdraw your payment from your deposit or other asset account. We will process checks You must contact us within 60 days after the error appeared on your electronically by transmitting the amount of the check, routing number, statement. account number and check serial number to your financial institution, You must notify us of any po...   \n",
       "111631                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        AMERICAN Platinum Card® p. 3/12 EXPRESS JAMES C RAWSON Closing Date 04/13/22 Account Ending 5-82006 Customer Care & Billing Inquiries 1-800-525-3355 International Collect 1-954-473-2123 Website: americanexpress.com Cash Advance at ATMs Inquiries 1-800-CASH-NOW Large Print & Braille Statements 1-800-525-3355 Customer Care & Billing Inquiries Payments P.O. BOX 981535 P.O. BOX 650448 EL PASO, TX DALLAS TX 75265- Hearing Impaired 79998-1535 0448 Online chat at americanexpress.com or use Relay dial 711 and 1-800-525-3355 For more information on your Pay Over Time Limit and your purchasing options, please see page 10 Reminder about changes to Pay Over Time As a reminder, we're making a change to Pay Over Time as of May 1, 2022, that will allow you to choose to carry a balance with interest on additional charges that were previously below the eligible amount. This will give you more payment flexibility with your everyday purchases. For further details, please refer to the notification that was sent to you in February 2022. If you have rejected this change to Pay Over Time (or do so by April 30, 2022), the minimum dollar amount for eligible Pay Over Time charges on your account will not change. If you have any questions, please call the Customer Care number on your billing statement. O, Congratulations! You saved with offers and benefits this statement period. Please refer to the Payments and Credits section of your statement. View all available offers and benefits when you log in to your online Card account at americanexpress.com Find local spots near you LET'S GRAB A TABLE. LET'S GO SHOP SMALL. By eating local, you support the small businesses at the heart of your community. Visit ShopSmall.com to learn more. Scan code with your smartphone camera Payments and Credits Summary Pay Over Time / Pay In Full Cash Advance + Tota Payments -$1,686.37 -$10,114.87 -$11,801.24 Credits JAMES C RAWSON 5-82006 -$55.45 -$2,726.34 -$2,781.79 Total Payments and Credits -$1,741.82 -$12,841.21 -$14,583.03 Detail *Indicates posting date - denotes Pay Over Time and/or Cash Advance activity Payments Amount 03/15/22* JAMES C RAWSON ONLINE PAYMENT - THANK YOU $3,000.00 03/25/22* JAMES C RAWSON ONLINE PAYMENT - THANK YOU $2,500.00 03/31/22* JAMES C RAWSON ONLINE PAYMENT - THANK YOU -$6,301.24 Credits Amount Continued on reverse   \n",
       "111632                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      JAMES C RAWSON Account Ending 5-82006 p. 4/12 Detail Continued *Indicates posting date - denotes Pay Over Time and/or Cash Advance activity Amount 03/26/22 JAMES C RAWSON UNITED AIRLINES -$207.00* TX HOUSTON UNITED AIRLINES From: To: Carrier: Class: CHICAGO O'HARE INT CHICAGO O'HARE INT UA 00 Ticket Number: 01699804726480 Date of Departure: 03/26 Passenger Name: RAWSON /OTHER Document Type: SUPPORTED REFUND 03/26/22 JAMES C RAWSON UNITED AIRLINES -$49.00 HOUSTON TX UNITED AIRLINES From: To: Carrier: Class: CHICAGO O'HARE INT CHICAGO O'HARE INT UA 00 Ticket Number: 01699804726491 Date of Departure: 03/26 Passenger Name: RAWSON /OTHER Document Type: SUPPORTED REFUND 03/26/22 JAMES C RAWSON UNITED AIRLINES -$240.00 * HOUSTON TX UNITED AIRLINES From: To: Carrier: Class CHICAGO O'HARE INT CHICAGO O'HARE INT UA 00 Ticket Number: 01699804728952 Date of Departure: 03/26 Passenger Name: RAWSON /OTHER Document Type: SUPPORTED REFUND 03/28/22 JAMES C RAWSON UNITED AIRLINES -$1,039.67 + HOUSTON TX UNITED AIRLINES From: To: Carrier: Class DENPASAR BALI SINGAPORE CHANGI A SQ 00 SAN FRANCISCO INTL UA 00 DENVER INTL APT UA 00 ALBUQUERQUE UA Ticket Number: 01624025800374 00 Date of Departure: 06/14 Passenger Name: RAWSON/JAMES Document Type: SUPPORTED REFUND 03/28/22 JAMES C RAWSON UNITED AIRLINES -$1,039.67 * HOUSTON TX UNITED AIRLINES From: To: Carrier: Class: DENPASAR BALI SINGAPORE CHANGI A SO 00 SAN FRANCISCO INTL UA 00 DENVER INTL APT UA 00 ALBUQUERQUE UA 00 Ticket Number: 01624025802765 Date of Departure: 06/14 Passenger Name: RAWSON/JAMES Document Type: SUPPORTED REFUND 03/29/22* JAMES C RAWSON AMEX Airline Fee Reimbursement -$200.00 * TRANSACTION PROCESSED BY AMERICAN EXPRESS 04/07/22 JAMES C RAWSON SIRIUS RADIO INC -$6.45 NEW YORK Amex Digital Ent New Charges Summary Pay In Full Pay Over Time + Tota JAMES C RAWSON 5-82006 $2,083.66 $8,526.97 $10,610.63 AUDREY MAE N RAWSON 5-82014 $639.55 $676.88 $1,316.43 Total New Charges $2,723.21 $9,203.85 $11,927.06 Continued on next page   \n",
       "111633                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             AMERICAN Platinum Card® p. 5/12 EXPRESS JAMES C RAWSON Closing Date 04/13/22 Account Ending 5-82006 Detail + - denote: Pay Over Time and/or Cash Advance activity JAMES C RAWSON Card Ending 5-82006 Foreign Spend Amount GOOGLE*YOUTUBEPREMIUM GOOGLE PAYMENT G.CO HELPPAY# 03/14/22 $12.55 CABLE & PAY TV GOOGLE*YOUTUBE SUPER GOOGLE PAYMENT 03/15/22 G.CO HELPPAY# $2.09 VIDEO PRODUCTION 03/16/22 TACO BELL 05262 0526 BERNALILLO NM $7.03 505-867-0747 03/16/22 TESLA PALO ALTO $250.00 * AUTO SERVICE 03/17/22 PF CHANG'S ALBUQUERQUE NM $46.02 8464780747816965 871070 FOOD/BEVERAGE 03/19/22 S-A BBQ TIN CAN ALLEY Albuquerque NM $37.21 squareup.com/receipts TIN CAN ALLEY 156176060886851 ALBUQUERQUE NM 03/19/22 $47.00 BREWMAIN@PROCESSLOCAL.COM 03/19/22 SMITHS FOOD #4459 000004459 ALBUQUERQUE NM $63.11 8666111979 GROCERY STORES 03/19/22 TONAL SYSTEMS, INC SAN FRANCISCO CA $49.00 +18556986625 03/23/22 TACO BELL 05262 0526 BERNALILLO NM $7.03 505-867-0747 03/23/22 AMAZON MUSIC*1N1C50250 888-802-3080 WA $4.30 DIGITAL 03/23/22 AMAZON.COM*1N6021UM0 AMZN.COM/BILL WA $23.74 MERCHANDISE AMZN.COM/BILL 03/23/22 AMAZON.COM*1N9U078X2 WA $23.74 MERCHANDISE 03/25/22 UNITED AIRLINES HOUSTON TX $240.00 * UNITED AIRLINES From: Carrier: Class: SINGAPORE CHANGI A SAN FRANCISCO INTL UA 00 Ticket Number: 01699804728952 Date of Departure: 06/15 Passenger Name: RAWSON /ECONOMY PLUS S Document Type: PREFERRED SEAT UPGRADE 03/25/22 UNITED AIRLINES HOUSTON TX $207.00 * UNITED AIRLINES From: To: Carrier: Class SINGAPORE CHANGI A SAN FRANCISCO INTL 00 Ticket Number: 01699804726480 Date of Departure: 06/15 Passenger Name: RAWSON /ECONOMY PLUS S Document Type: PREFERRED SEAT UPGRADE 03/25/22 UNITED AIRLINES HOUSTON TX $49.00 UNITED AIRLINES From: To: Carrier: Class DENVER INTL APT ALBUQUERQUE UA 00 Ticket Number: 01699804726491 Date of Departure: 06/15 Passenger Name: RAWSON /ECONOMY PLUS S Document Type: PREFERRED SEAT UPGRADE Continued on reverse   \n",
       "\n",
       "                              category  type            date ogr/aug page#  \\\n",
       "111629  Non-Mortgage Account Statement  NMIC  20220722194403     org   509   \n",
       "111630  Non-Mortgage Account Statement  NMIC  20220722194403     org   510   \n",
       "111631  Non-Mortgage Account Statement  NMIC  20220722194403     org   511   \n",
       "111632  Non-Mortgage Account Statement  NMIC  20220722194403     org   512   \n",
       "111633  Non-Mortgage Account Statement  NMIC  20220722194403     org   513   \n",
       "\n",
       "        angle renamed category  \n",
       "111629    0.0               No  \n",
       "111630    0.0               No  \n",
       "111631    0.0               No  \n",
       "111632    0.0               No  \n",
       "111633    0.0               No  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['category']=='Non-Mortgage Account Statement'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8174695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "\n",
    "cats = ['Retirement Account Statement(s)',\n",
    "        'Mortgage Statement',\n",
    "        'Non-Mortgage Account Statement',\n",
    "        'Bank Statement',\n",
    "        'Purchase Agreement',\n",
    "        'Rental Agreements(s)',\n",
    "        'Hazard Insurance Dec Page - Initial',\n",
    "        'Divorce Decree / Child Support',\n",
    "        'Bankruptcy Papers']\n",
    "\n",
    "# cats = ['Retirement Account Statement(s)',\n",
    "#         'Mortgage Statement',\n",
    "#         'Bank Statement']\n",
    "        \n",
    "        \n",
    "for category in data['category']:\n",
    "    if category not in cats:\n",
    "        temp.append('others')\n",
    "    else:\n",
    "#         temp.append('focused')\n",
    "        temp.append(category)\n",
    "data['new_category'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "785bbbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"label_dict = {}\\nlabel_dict['focused'] = 1\\nlabel_dict['others'] = 0\\nlabel_dict\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''label_dict = {}\n",
    "label_dict['focused'] = 1\n",
    "label_dict['others'] = 0\n",
    "label_dict'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "74388380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'others': 0,\n",
       " 'Retirement Account Statement(s)': 1,\n",
       " 'Mortgage Statement': 2,\n",
       " 'Non-Mortgage Account Statement': 3,\n",
       " 'Bank Statement': 4,\n",
       " 'Purchase Agreement': 5,\n",
       " 'Rental Agreements(s)': 6,\n",
       " 'Hazard Insurance Dec Page - Initial': 7,\n",
       " 'Divorce Decree / Child Support': 8,\n",
       " 'Bankruptcy Papers': 9}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = data.new_category.unique()\n",
    "\n",
    "label_dict = {}\n",
    "label_dict['others']=0\n",
    "for i,cat in enumerate(cats):\n",
    "    label_dict[cat]=i+1\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c784460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADR</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>ogr/aug</th>\n",
       "      <th>page#</th>\n",
       "      <th>angle</th>\n",
       "      <th>renamed category</th>\n",
       "      <th>new_category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADR-2022-100004473184</td>\n",
       "      <td>loanDepot Branch: 102 - Cerritos Branch - Cerritos, CA NMLS # 174457 Set-Up Submission Form Borrower: Suzi Builder Loan Officer: POS Banker Credit Reference: 116287576930000 DU Case file ID: 1626158786 C.O.E.: 8/7/2022 Submitted: 7/7/2022 Prospect Loan#: 3001618980 Sales Price: $500,500.00 Appraised Value: $500,500.00 Loan Amt: $250,000.00 Rate: 5.250% Origination: $0.00 Discount: 0.086% LTV: 49.950% CLTV:49.950% Property Address: 432 Lake Front, Orwigsburg, PA 17961 Community Name: Loan Purpose: X Purchase Rate/Term Refi If Applicable 2nd loan Rate Term: 180 Cash-Out Refi Streamline Refi VA Non-Allowable Loan Type: X Conventional FHA USDA Seller Paid VA Other {Funding Fee: $ Exempt} Lender Paid SPECIFY PRODUCT CODE MSA/Builder FROM RATE SHEET Must select none or appropriate (Code is located at the bottom of the column of the program you are pricing) MSA/Desk Rental/Builder Bond: Yes Program 1: Program 2: Construction: Property Type: New Construction X SFR Detached SFR Attached Low Rise Condo Mid Rise Condo High Rise Condo Manufactured Home PUD Modular 2 Unit 3 Unit 4 Unit Co-op Other Occupancy Status Escrows Seller Credit: $ 0.00 X Primary 2nd Home Investment Impound: Transfer Taxes: $ 0.00 Waive Hazard: $ 100.00 Taxes: $ 0.00 MI: $ 0.00 Flood: $ Title Company Title Company Name: ServiceLink, LLC Contact: Address: 1355 Cherrington Pkwy, Moon Township, PA Phone: (800)439-5451 Fax: Email: kim.arndt@svclnk.com Hazard Insurance Insurance Company: Contact: Address: Phone: Fax: Email: Real Estate Agents: Buyer's Agent: Phone: Fax: Email: Seller's Agent: Phone: Fax: Email: Loan Officers: Please use this section to make comments regarding the loan. Mortgage Insurance - MI Lock Status Lender Paid MI (LPMI) Split MI Option Locked: Yes X No #Days 45 Borrower Paid MI (BPMI) Program 1 .05 Program 2 .75 Monthly Program 3 1.00 Single Premium Program 4 1.25 Single Premium Financed Program 5 1.50 Single Premium - Split cash/financed Split Premium (UFMIP cash) Program 6 1.75 100000 Split Premium (UFMIP financed) Empower Form (05/2014)</td>\n",
       "      <td>Setup Submission Form</td>\n",
       "      <td>LD</td>\n",
       "      <td>20220722123724</td>\n",
       "      <td>org</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ADR  \\\n",
       "0  ADR-2022-100004473184   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text  \\\n",
       "0   loanDepot Branch: 102 - Cerritos Branch - Cerritos, CA NMLS # 174457 Set-Up Submission Form Borrower: Suzi Builder Loan Officer: POS Banker Credit Reference: 116287576930000 DU Case file ID: 1626158786 C.O.E.: 8/7/2022 Submitted: 7/7/2022 Prospect Loan#: 3001618980 Sales Price: $500,500.00 Appraised Value: $500,500.00 Loan Amt: $250,000.00 Rate: 5.250% Origination: $0.00 Discount: 0.086% LTV: 49.950% CLTV:49.950% Property Address: 432 Lake Front, Orwigsburg, PA 17961 Community Name: Loan Purpose: X Purchase Rate/Term Refi If Applicable 2nd loan Rate Term: 180 Cash-Out Refi Streamline Refi VA Non-Allowable Loan Type: X Conventional FHA USDA Seller Paid VA Other {Funding Fee: $ Exempt} Lender Paid SPECIFY PRODUCT CODE MSA/Builder FROM RATE SHEET Must select none or appropriate (Code is located at the bottom of the column of the program you are pricing) MSA/Desk Rental/Builder Bond: Yes Program 1: Program 2: Construction: Property Type: New Construction X SFR Detached SFR Attached Low Rise Condo Mid Rise Condo High Rise Condo Manufactured Home PUD Modular 2 Unit 3 Unit 4 Unit Co-op Other Occupancy Status Escrows Seller Credit: $ 0.00 X Primary 2nd Home Investment Impound: Transfer Taxes: $ 0.00 Waive Hazard: $ 100.00 Taxes: $ 0.00 MI: $ 0.00 Flood: $ Title Company Title Company Name: ServiceLink, LLC Contact: Address: 1355 Cherrington Pkwy, Moon Township, PA Phone: (800)439-5451 Fax: Email: kim.arndt@svclnk.com Hazard Insurance Insurance Company: Contact: Address: Phone: Fax: Email: Real Estate Agents: Buyer's Agent: Phone: Fax: Email: Seller's Agent: Phone: Fax: Email: Loan Officers: Please use this section to make comments regarding the loan. Mortgage Insurance - MI Lock Status Lender Paid MI (LPMI) Split MI Option Locked: Yes X No #Days 45 Borrower Paid MI (BPMI) Program 1 .05 Program 2 .75 Monthly Program 3 1.00 Single Premium Program 4 1.25 Single Premium Financed Program 5 1.50 Single Premium - Split cash/financed Split Premium (UFMIP cash) Program 6 1.75 100000 Split Premium (UFMIP financed) Empower Form (05/2014)   \n",
       "\n",
       "                category type            date ogr/aug page#  angle  \\\n",
       "0  Setup Submission Form   LD  20220722123724     org     1    0.0   \n",
       "\n",
       "  renamed category new_category  label  \n",
       "0               No       others      0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'] = data.new_category.replace(label_dict)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7a3cf7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.50, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "78b8762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84588, 11)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8e0d7d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67670, 11)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.sample(frac=0.80, random_state=10)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6efd3751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16918, 11)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.drop(df.index).reset_index(drop=True)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "97770f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "others                                 9600\n",
       "Bank Statement                         3146\n",
       "Retirement Account Statement(s)         961\n",
       "Hazard Insurance Dec Page - Initial     812\n",
       "Divorce Decree / Child Support          718\n",
       "Rental Agreements(s)                    573\n",
       "Mortgage Statement                      569\n",
       "Purchase Agreement                      417\n",
       "Bankruptcy Papers                        99\n",
       "Non-Mortgage Account Statement           23\n",
       "Name: new_category, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e8803e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "others                                 37940\n",
       "Bank Statement                         12673\n",
       "Retirement Account Statement(s)         3983\n",
       "Hazard Insurance Dec Page - Initial     3245\n",
       "Divorce Decree / Child Support          2699\n",
       "Rental Agreements(s)                    2392\n",
       "Mortgage Statement                      2279\n",
       "Purchase Agreement                      1971\n",
       "Bankruptcy Papers                        399\n",
       "Non-Mortgage Account Statement            89\n",
       "Name: new_category, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "de814859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1784,  1.6990,  0.5340,  3.4333,  2.9693,  2.0854,  2.8290,  2.5072,\n",
       "        16.9599, 76.0337])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classweight = torch.tensor(class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                             classes=df['new_category'].unique().tolist(),\n",
    "                                                             y=df['new_category'].values.tolist()), dtype=torch.float)\n",
    "classweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "21062e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADR</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>ogr/aug</th>\n",
       "      <th>page#</th>\n",
       "      <th>angle</th>\n",
       "      <th>renamed category</th>\n",
       "      <th>new_category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADR-2022-100004517751</td>\n",
       "      <td>12/31/20 2020 FEDERAL DEPRECIATION SCHEDULE PAGE 2 J&amp;D TRANSPORT INC 82-5297252 PRIOR CUR SPECIAL 179/ PRIOR SALVAG DATE DATE COST/ BUS. 179 DEPR. BONUS/ DEC. BAL /BASIS DEPR. PRIOR CURRENT NO. DESCRIPTION ACQUIRED SOLD BASIS PCT. BONUS ALLOW. SP. DEPR. DEPR. REDUCT BASIS DEPR. METHOD LIFE RATE DEPR. 21 WELDER ** 11/26/20 5,073 5,073 200DB HY 5 .20000 1,015 22 VAN TRAILER 53010 ** 9/24/20 3,000 3,000 200DB HY 5 .20000 600 23 VAN TRAILER 45871 ** 9/24/20 3,000 3,000 200DB HY 5 .20000 600 TOTAL MACHINERY AND EQUIPME 115,353 0 0 16,040 0 0 99,313 12,186 27,174 TOTAL DEPRECIATION 490,418 0 0 16,040 0 0 474,378 72,030 138,093 GRAND TOTAL DEPRECIATION 490,418 0 0 16,040 0 0 474,378 72,030 138,093 == DEPRECIATION ASSETS SOLD 3,040 0 0 3,040 0 0 0 0 0 DEPR REMAINING ASSETS 487,378 0 0 13,000 0 0 474,378 72,030 138,093 **ASSET INCLUDED IN UNADJUSTED BASIS IMMEDIATELY AFTER ACQUISITION FOR THE QBI CALCULATION.</td>\n",
       "      <td>Tax Return - Business</td>\n",
       "      <td>LD</td>\n",
       "      <td>20220722123724</td>\n",
       "      <td>org</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>others</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ADR  \\\n",
       "0  ADR-2022-100004517751   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "0   12/31/20 2020 FEDERAL DEPRECIATION SCHEDULE PAGE 2 J&D TRANSPORT INC 82-5297252 PRIOR CUR SPECIAL 179/ PRIOR SALVAG DATE DATE COST/ BUS. 179 DEPR. BONUS/ DEC. BAL /BASIS DEPR. PRIOR CURRENT NO. DESCRIPTION ACQUIRED SOLD BASIS PCT. BONUS ALLOW. SP. DEPR. DEPR. REDUCT BASIS DEPR. METHOD LIFE RATE DEPR. 21 WELDER ** 11/26/20 5,073 5,073 200DB HY 5 .20000 1,015 22 VAN TRAILER 53010 ** 9/24/20 3,000 3,000 200DB HY 5 .20000 600 23 VAN TRAILER 45871 ** 9/24/20 3,000 3,000 200DB HY 5 .20000 600 TOTAL MACHINERY AND EQUIPME 115,353 0 0 16,040 0 0 99,313 12,186 27,174 TOTAL DEPRECIATION 490,418 0 0 16,040 0 0 474,378 72,030 138,093 GRAND TOTAL DEPRECIATION 490,418 0 0 16,040 0 0 474,378 72,030 138,093 == DEPRECIATION ASSETS SOLD 3,040 0 0 3,040 0 0 0 0 0 DEPR REMAINING ASSETS 487,378 0 0 13,000 0 0 474,378 72,030 138,093 **ASSET INCLUDED IN UNADJUSTED BASIS IMMEDIATELY AFTER ACQUISITION FOR THE QBI CALCULATION.   \n",
       "\n",
       "                category type            date ogr/aug page#  angle  \\\n",
       "0  Tax Return - Business   LD  20220722123724     org    34    0.0   \n",
       "\n",
       "  renamed category new_category  label  \n",
       "0               No       others      0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9c4dd54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"possible_labels = df.new_category.unique()\\n\\nlabel_dict = {}\\nlabel_dict['others']=0\\nfor i,cat in enumerate(cats):\\n    label_dict[cat]=i+1\\n#for index, possible_label in enumerate(possible_labels):\\n#    label_dict[possible_label] = index\\nlabel_dict\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''possible_labels = df.new_category.unique()\n",
    "\n",
    "label_dict = {}\n",
    "label_dict['others']=0\n",
    "for i,cat in enumerate(cats):\n",
    "    label_dict[cat]=i+1\n",
    "#for index, possible_label in enumerate(possible_labels):\n",
    "#    label_dict[possible_label] = index\n",
    "label_dict'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "73c25afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size=0.20, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7186a08d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADR</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>ogr/aug</th>\n",
       "      <th>page#</th>\n",
       "      <th>angle</th>\n",
       "      <th>renamed category</th>\n",
       "      <th>new_category</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADR-2022-100004517751</td>\n",
       "      <td>12/31/20 2020 FEDERAL DEPRECIATION SCHEDULE PAGE 2 J&amp;D TRANSPORT INC 82-5297252 PRIOR CUR SPECIAL 179/ PRIOR SALVAG DATE DATE COST/ BUS. 179 DEPR. BONUS/ DEC. BAL /BASIS DEPR. PRIOR CURRENT NO. DESCRIPTION ACQUIRED SOLD BASIS PCT. BONUS ALLOW. SP. DEPR. DEPR. REDUCT BASIS DEPR. METHOD LIFE RATE DEPR. 21 WELDER ** 11/26/20 5,073 5,073 200DB HY 5 .20000 1,015 22 VAN TRAILER 53010 ** 9/24/20 3,000 3,000 200DB HY 5 .20000 600 23 VAN TRAILER 45871 ** 9/24/20 3,000 3,000 200DB HY 5 .20000 600 TOTAL MACHINERY AND EQUIPME 115,353 0 0 16,040 0 0 99,313 12,186 27,174 TOTAL DEPRECIATION 490,418 0 0 16,040 0 0 474,378 72,030 138,093 GRAND TOTAL DEPRECIATION 490,418 0 0 16,040 0 0 474,378 72,030 138,093 == DEPRECIATION ASSETS SOLD 3,040 0 0 3,040 0 0 0 0 0 DEPR REMAINING ASSETS 487,378 0 0 13,000 0 0 474,378 72,030 138,093 **ASSET INCLUDED IN UNADJUSTED BASIS IMMEDIATELY AFTER ACQUISITION FOR THE QBI CALCULATION.</td>\n",
       "      <td>Tax Return - Business</td>\n",
       "      <td>LD</td>\n",
       "      <td>20220722123724</td>\n",
       "      <td>org</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>others</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADR-2022-100004484554</td>\n",
       "      <td>Morgan Stanley CLIENT STATEMENT | For the Period April 1-30, 2022 Page 23 of 62 Select UMA Active Assets Account MSL FBO FRANK PELLI &amp; Account Summary 409-077646-303 ANITA K PELLI JT TEN ADDITIONAL ACCOUNT INFORMATION This Pericd This Year Category (4/1/22-4/30/22) (1/1/22-4/30/22) Foreign Tax Paid $107.89 $337.97 000042 M58820M1 001068</td>\n",
       "      <td>Retirement Account Statement(s)</td>\n",
       "      <td>LD</td>\n",
       "      <td>20220722123724</td>\n",
       "      <td>org</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Retirement Account Statement(s)</td>\n",
       "      <td>1</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ADR  \\\n",
       "0  ADR-2022-100004517751   \n",
       "1  ADR-2022-100004484554   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "0   12/31/20 2020 FEDERAL DEPRECIATION SCHEDULE PAGE 2 J&D TRANSPORT INC 82-5297252 PRIOR CUR SPECIAL 179/ PRIOR SALVAG DATE DATE COST/ BUS. 179 DEPR. BONUS/ DEC. BAL /BASIS DEPR. PRIOR CURRENT NO. DESCRIPTION ACQUIRED SOLD BASIS PCT. BONUS ALLOW. SP. DEPR. DEPR. REDUCT BASIS DEPR. METHOD LIFE RATE DEPR. 21 WELDER ** 11/26/20 5,073 5,073 200DB HY 5 .20000 1,015 22 VAN TRAILER 53010 ** 9/24/20 3,000 3,000 200DB HY 5 .20000 600 23 VAN TRAILER 45871 ** 9/24/20 3,000 3,000 200DB HY 5 .20000 600 TOTAL MACHINERY AND EQUIPME 115,353 0 0 16,040 0 0 99,313 12,186 27,174 TOTAL DEPRECIATION 490,418 0 0 16,040 0 0 474,378 72,030 138,093 GRAND TOTAL DEPRECIATION 490,418 0 0 16,040 0 0 474,378 72,030 138,093 == DEPRECIATION ASSETS SOLD 3,040 0 0 3,040 0 0 0 0 0 DEPR REMAINING ASSETS 487,378 0 0 13,000 0 0 474,378 72,030 138,093 **ASSET INCLUDED IN UNADJUSTED BASIS IMMEDIATELY AFTER ACQUISITION FOR THE QBI CALCULATION.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Morgan Stanley CLIENT STATEMENT | For the Period April 1-30, 2022 Page 23 of 62 Select UMA Active Assets Account MSL FBO FRANK PELLI & Account Summary 409-077646-303 ANITA K PELLI JT TEN ADDITIONAL ACCOUNT INFORMATION This Pericd This Year Category (4/1/22-4/30/22) (1/1/22-4/30/22) Foreign Tax Paid $107.89 $337.97 000042 M58820M1 001068   \n",
       "\n",
       "                          category type            date ogr/aug page#  angle  \\\n",
       "0            Tax Return - Business   LD  20220722123724     org    34    0.0   \n",
       "1  Retirement Account Statement(s)   LD  20220722123724     org    23    0.0   \n",
       "\n",
       "  renamed category                     new_category  label data_type  \n",
       "0               No                           others      0   not_set  \n",
       "1               No  Retirement Account Statement(s)      1   not_set  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9c62fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "99b2f578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ADR</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>ogr/aug</th>\n",
       "      <th>page#</th>\n",
       "      <th>angle</th>\n",
       "      <th>renamed category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_category</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Bank Statement</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>train</th>\n",
       "      <td>10138</td>\n",
       "      <td>10138</td>\n",
       "      <td>10138</td>\n",
       "      <td>10138</td>\n",
       "      <td>10138</td>\n",
       "      <td>10138</td>\n",
       "      <td>10138</td>\n",
       "      <td>10138</td>\n",
       "      <td>10138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "      <td>2535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Bankruptcy Papers</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>train</th>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Divorce Decree / Child Support</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>train</th>\n",
       "      <td>2159</td>\n",
       "      <td>2159</td>\n",
       "      <td>2159</td>\n",
       "      <td>2159</td>\n",
       "      <td>2159</td>\n",
       "      <td>2159</td>\n",
       "      <td>2159</td>\n",
       "      <td>2159</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Hazard Insurance Dec Page - Initial</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>train</th>\n",
       "      <td>2596</td>\n",
       "      <td>2596</td>\n",
       "      <td>2596</td>\n",
       "      <td>2596</td>\n",
       "      <td>2596</td>\n",
       "      <td>2596</td>\n",
       "      <td>2596</td>\n",
       "      <td>2596</td>\n",
       "      <td>2596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>649</td>\n",
       "      <td>649</td>\n",
       "      <td>649</td>\n",
       "      <td>649</td>\n",
       "      <td>649</td>\n",
       "      <td>649</td>\n",
       "      <td>649</td>\n",
       "      <td>649</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Mortgage Statement</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "      <td>1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>456</td>\n",
       "      <td>456</td>\n",
       "      <td>456</td>\n",
       "      <td>456</td>\n",
       "      <td>456</td>\n",
       "      <td>456</td>\n",
       "      <td>456</td>\n",
       "      <td>456</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Non-Mortgage Account Statement</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>train</th>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Purchase Agreement</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>train</th>\n",
       "      <td>1577</td>\n",
       "      <td>1577</td>\n",
       "      <td>1577</td>\n",
       "      <td>1577</td>\n",
       "      <td>1577</td>\n",
       "      <td>1577</td>\n",
       "      <td>1577</td>\n",
       "      <td>1577</td>\n",
       "      <td>1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Rental Agreements(s)</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>train</th>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>478</td>\n",
       "      <td>478</td>\n",
       "      <td>478</td>\n",
       "      <td>478</td>\n",
       "      <td>478</td>\n",
       "      <td>478</td>\n",
       "      <td>478</td>\n",
       "      <td>478</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Retirement Account Statement(s)</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>3187</td>\n",
       "      <td>3187</td>\n",
       "      <td>3187</td>\n",
       "      <td>3187</td>\n",
       "      <td>3187</td>\n",
       "      <td>3187</td>\n",
       "      <td>3187</td>\n",
       "      <td>3187</td>\n",
       "      <td>3187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>796</td>\n",
       "      <td>796</td>\n",
       "      <td>796</td>\n",
       "      <td>796</td>\n",
       "      <td>796</td>\n",
       "      <td>796</td>\n",
       "      <td>796</td>\n",
       "      <td>796</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">others</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>30352</td>\n",
       "      <td>30352</td>\n",
       "      <td>30352</td>\n",
       "      <td>30352</td>\n",
       "      <td>30352</td>\n",
       "      <td>30352</td>\n",
       "      <td>30352</td>\n",
       "      <td>30352</td>\n",
       "      <td>30352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>7588</td>\n",
       "      <td>7588</td>\n",
       "      <td>7588</td>\n",
       "      <td>7588</td>\n",
       "      <td>7588</td>\n",
       "      <td>7588</td>\n",
       "      <td>7588</td>\n",
       "      <td>7588</td>\n",
       "      <td>7588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       ADR   text  category  \\\n",
       "new_category                        label data_type                           \n",
       "Bank Statement                      4     train      10138  10138     10138   \n",
       "                                          val         2535   2535      2535   \n",
       "Bankruptcy Papers                   9     train        319    319       319   \n",
       "                                          val           80     80        80   \n",
       "Divorce Decree / Child Support      8     train       2159   2159      2159   \n",
       "                                          val          540    540       540   \n",
       "Hazard Insurance Dec Page - Initial 7     train       2596   2596      2596   \n",
       "                                          val          649    649       649   \n",
       "Mortgage Statement                  2     train       1823   1823      1823   \n",
       "                                          val          456    456       456   \n",
       "Non-Mortgage Account Statement      3     train         71     71        71   \n",
       "                                          val           18     18        18   \n",
       "Purchase Agreement                  5     train       1577   1577      1577   \n",
       "                                          val          394    394       394   \n",
       "Rental Agreements(s)                6     train       1914   1914      1914   \n",
       "                                          val          478    478       478   \n",
       "Retirement Account Statement(s)     1     train       3187   3187      3187   \n",
       "                                          val          796    796       796   \n",
       "others                              0     train      30352  30352     30352   \n",
       "                                          val         7588   7588      7588   \n",
       "\n",
       "                                                      type   date  ogr/aug  \\\n",
       "new_category                        label data_type                          \n",
       "Bank Statement                      4     train      10138  10138    10138   \n",
       "                                          val         2535   2535     2535   \n",
       "Bankruptcy Papers                   9     train        319    319      319   \n",
       "                                          val           80     80       80   \n",
       "Divorce Decree / Child Support      8     train       2159   2159     2159   \n",
       "                                          val          540    540      540   \n",
       "Hazard Insurance Dec Page - Initial 7     train       2596   2596     2596   \n",
       "                                          val          649    649      649   \n",
       "Mortgage Statement                  2     train       1823   1823     1823   \n",
       "                                          val          456    456      456   \n",
       "Non-Mortgage Account Statement      3     train         71     71       71   \n",
       "                                          val           18     18       18   \n",
       "Purchase Agreement                  5     train       1577   1577     1577   \n",
       "                                          val          394    394      394   \n",
       "Rental Agreements(s)                6     train       1914   1914     1914   \n",
       "                                          val          478    478      478   \n",
       "Retirement Account Statement(s)     1     train       3187   3187     3187   \n",
       "                                          val          796    796      796   \n",
       "others                              0     train      30352  30352    30352   \n",
       "                                          val         7588   7588     7588   \n",
       "\n",
       "                                                     page#  angle  \\\n",
       "new_category                        label data_type                 \n",
       "Bank Statement                      4     train      10138  10138   \n",
       "                                          val         2535   2535   \n",
       "Bankruptcy Papers                   9     train        319    319   \n",
       "                                          val           80     80   \n",
       "Divorce Decree / Child Support      8     train       2159   2159   \n",
       "                                          val          540    540   \n",
       "Hazard Insurance Dec Page - Initial 7     train       2596   2596   \n",
       "                                          val          649    649   \n",
       "Mortgage Statement                  2     train       1823   1823   \n",
       "                                          val          456    456   \n",
       "Non-Mortgage Account Statement      3     train         71     71   \n",
       "                                          val           18     18   \n",
       "Purchase Agreement                  5     train       1577   1577   \n",
       "                                          val          394    394   \n",
       "Rental Agreements(s)                6     train       1914   1914   \n",
       "                                          val          478    478   \n",
       "Retirement Account Statement(s)     1     train       3187   3187   \n",
       "                                          val          796    796   \n",
       "others                              0     train      30352  30352   \n",
       "                                          val         7588   7588   \n",
       "\n",
       "                                                     renamed category  \n",
       "new_category                        label data_type                    \n",
       "Bank Statement                      4     train                 10138  \n",
       "                                          val                    2535  \n",
       "Bankruptcy Papers                   9     train                   319  \n",
       "                                          val                      80  \n",
       "Divorce Decree / Child Support      8     train                  2159  \n",
       "                                          val                     540  \n",
       "Hazard Insurance Dec Page - Initial 7     train                  2596  \n",
       "                                          val                     649  \n",
       "Mortgage Statement                  2     train                  1823  \n",
       "                                          val                     456  \n",
       "Non-Mortgage Account Statement      3     train                    71  \n",
       "                                          val                      18  \n",
       "Purchase Agreement                  5     train                  1577  \n",
       "                                          val                     394  \n",
       "Rental Agreements(s)                6     train                  1914  \n",
       "                                          val                     478  \n",
       "Retirement Account Statement(s)     1     train                  3187  \n",
       "                                          val                     796  \n",
       "others                              0     train                 30352  \n",
       "                                          val                    7588  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['new_category', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c776d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "import glob\n",
    "import math\n",
    "\n",
    "path = \"./tempmortbert/model\"\n",
    "\n",
    "for modelpath in glob.iglob(path):\n",
    "    print('Model: ', modelpath)\n",
    "    tokenizer = BertTokenizer.from_pretrained(modelpath, use_fast = False, do_lower_case=True)\n",
    "#     model = AutoModelForMaskedLM.from_pretrained(modelpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "80b0abce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mmortgage/MultiPage_Classification/classification_service/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2285: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoded_data_train \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_max_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m encoded_data_val \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m     12\u001b[0m     df[df\u001b[38;5;241m.\u001b[39mdata_type\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mvalues, \n\u001b[1;32m     13\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m )\n",
      "File \u001b[0;32m/data/mmortgage/MultiPage_Classification/classification_service/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2668\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2658\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2659\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2660\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2661\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2665\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2666\u001b[0m )\n\u001b[0;32m-> 2668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2670\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2685\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/mmortgage/MultiPage_Classification/classification_service/lib/python3.8/site-packages/transformers/tokenization_utils.py:730\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    728\u001b[0m     ids, pair_ids \u001b[38;5;241m=\u001b[39m ids_or_pair_ids\n\u001b[0;32m--> 730\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(pair_ids) \u001b[38;5;28;01mif\u001b[39;00m pair_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    732\u001b[0m input_ids\u001b[38;5;241m.\u001b[39mappend((first_ids, second_ids))\n",
      "File \u001b[0;32m/data/mmortgage/MultiPage_Classification/classification_service/lib/python3.8/site-packages/transformers/tokenization_utils.py:697\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_input_ids\u001b[39m(text):\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 697\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/data/mmortgage/MultiPage_Classification/classification_service/lib/python3.8/site-packages/transformers/tokenization_utils.py:513\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m     escaped_special_toks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    510\u001b[0m         re\u001b[38;5;241m.\u001b[39mescape(s_tok) \u001b[38;5;28;01mfor\u001b[39;00m s_tok \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_no_split_tokens \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_special_tokens)\n\u001b[1;32m    511\u001b[0m     ]\n\u001b[1;32m    512\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(escaped_special_toks) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)|\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(.+?)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 513\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m no_split_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_no_split_tokens)\n\u001b[1;32m    516\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens_trie\u001b[38;5;241m.\u001b[39msplit(text)\n",
      "File \u001b[0;32m/usr/lib/python3.8/re.py:208\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/mmortgage/MultiPage_Classification/classification_service/lib/python3.8/site-packages/transformers/tokenization_utils.py:513\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize.<locals>.<lambda>\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m    509\u001b[0m     escaped_special_toks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    510\u001b[0m         re\u001b[38;5;241m.\u001b[39mescape(s_tok) \u001b[38;5;28;01mfor\u001b[39;00m s_tok \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_no_split_tokens \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_special_tokens)\n\u001b[1;32m    511\u001b[0m     ]\n\u001b[1;32m    512\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(escaped_special_toks) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)|\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(.+?)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 513\u001b[0m     text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(pattern, \u001b[38;5;28;01mlambda\u001b[39;00m m: m\u001b[38;5;241m.\u001b[39mgroups()[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m m\u001b[38;5;241m.\u001b[39mgroups()[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlower(), text)\n\u001b[1;32m    515\u001b[0m no_split_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_no_split_tokens)\n\u001b[1;32m    516\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens_trie\u001b[38;5;241m.\u001b[39msplit(text)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].text.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=512, \n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].text.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "277dad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "252ad2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59692c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              shuffle=True,\n",
    "                              num_workers=0, \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   shuffle=False,\n",
    "                                   num_workers=0, \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19c6a2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3384"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "871ed309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108288"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader_train)*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f436f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 dropout=0.1, \n",
    "                 BERTconfig=False, \n",
    "                 attention_heads=12, \n",
    "                 hidden_layers=12, \n",
    "                 numclass=1,\n",
    "                 hidden_dropout_prob=0.1,\n",
    "                 hidden_act='gelu',\n",
    "                 position_embedding_type='absolute'):\n",
    "        \n",
    "        #self.attention_heads = attention_heads\n",
    "        super(BertClassifier, self).__init__()\n",
    "        \n",
    "        if BERTconfig:\n",
    "            configuration = BertConfig(num_attention_heads= attention_heads, \n",
    "                                       num_hidden_layers= hidden_layers)   \n",
    "        else:\n",
    "            configuration = BertConfig()\n",
    "        #self.bert = BertModel.from_pretrained('bert-base-uncased', output_attentions=attention)\n",
    "        #print(configuration)\n",
    "        self.bert = BertModel(configuration)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, numclass, bias=True)\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a21c832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATTENTION = 12\n",
    "HIDDEN_LAYER = 1\n",
    "CLASSES = len(label_dict)\n",
    "\n",
    "\n",
    "model = BertClassifier(dropout=0.3, \n",
    "                       BERTconfig=True, \n",
    "                       attention_heads=ATTENTION,\n",
    "                       hidden_layers=HIDDEN_LAYER,\n",
    "                       numclass= CLASSES,\n",
    "                       hidden_dropout_prob=0.3,\n",
    "                       position_embedding_type='absolute')\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 3\n",
    "\n",
    "save_model = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=classweight.to(device), reduction='mean')\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8,\n",
    "                  no_deprecation_warning=True)\n",
    "                  \n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=250,\n",
    "                                            num_training_steps=len(dataloader_train)*EPOCH)\n",
    "\n",
    "\n",
    "logs = []\n",
    "i=0\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    print('epoch--- ',epoch+1)\n",
    "    \n",
    "    for train_input in tqdm(dataloader_train):\n",
    "        i=i+1\n",
    "        model.zero_grad()\n",
    "        input_id = train_input[0].to(device)\n",
    "        mask = train_input[1].to(device)\n",
    "        train_label = train_input[2].to(device)\n",
    "        output = model(input_id, mask)\n",
    "        batch_loss = criterion(output, train_label)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if(i%save_model==0):\n",
    "            label_train =  torch.tensor([], dtype=torch.uint8).to(device)\n",
    "            pred_train = torch.tensor([], dtype=torch.uint8).to(device)\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_eval in dataloader_train:\n",
    "                input_id = train_eval[0].to(device)\n",
    "                mask = train_eval[1].to(device)\n",
    "                train_label = train_eval[2].to(device)\n",
    "                output = model(input_id, mask)\n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                label_train = torch.cat((label_train, train_label), 0)\n",
    "                pred_train = torch.cat((pred_train, output.argmax(dim=1)), 0)\n",
    "\n",
    "            label_train = label_train.detach().cpu().numpy()\n",
    "            pred_train = pred_train.detach().cpu().numpy()\n",
    "            total_acc_train = accuracy_score(label_train, pred_train)\n",
    "            total_f1_train = f1_score(label_train, pred_train, average='weighted')\n",
    "            total_loss_train = total_loss_train/(len(dataloader_train)*batch_size)\n",
    "            \n",
    "\n",
    "\n",
    "            label_val =  torch.tensor([], dtype=torch.uint8).to(device)\n",
    "            pred_val = torch.tensor([], dtype=torch.uint8).to(device)\n",
    "            total_loss_val = 0\n",
    "\n",
    "            for val_input in dataloader_validation:\n",
    "                input_id = val_input[0].to(device)\n",
    "                mask = val_input[1].to(device)\n",
    "                val_label = val_input[2].to(device)\n",
    "                output = model(input_id, mask)\n",
    "                batch_loss = criterion(output, val_label)\n",
    "                total_loss_val += batch_loss.item()\n",
    "                label_val = torch.cat((label_val, val_label), 0)\n",
    "                pred_val = torch.cat((pred_val, output.argmax(dim=1)), 0)\n",
    "\n",
    "            label_val = label_val.detach().cpu().numpy()\n",
    "            pred_val = pred_val.detach().cpu().numpy()\n",
    "            total_acc_val = accuracy_score(label_val, pred_val)\n",
    "            total_f1_val = f1_score(label_val, pred_val, average='weighted')\n",
    "            total_loss_val = total_loss_val/(len(dataloader_validation)*batch_size)\n",
    "            \n",
    "            print('train_accuracy: ', total_acc_train, ', train_f1: ', total_f1_train, ', train_loss: ', total_loss_train)\n",
    "            print('val_accuracy: ', total_acc_val, ',  val_f1: ', total_f1_val, ', val_loss: ', total_loss_val)\n",
    "\n",
    "            torch.save(model.state_dict(), \n",
    "                       f'/mnt/custommodel/BASE_BERT_encoder{HIDDEN_LAYER}_attention{ATTENTION}_epoch{i}.model')\n",
    "\n",
    "            logs.append({'epoch': i,\n",
    "                     'train_accuracy': total_acc_train,\n",
    "                     'train_f1': total_f1_train,\n",
    "                     'train_loss': total_loss_train,\n",
    "                     'val_accuracy': total_acc_val,\n",
    "                     'val_f1': total_f1_val,\n",
    "                     'val_loss': total_loss_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff004a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.DataFrame(logs)\n",
    "log['val_loss'] = log['val_loss'].round(3)\n",
    "log['train_loss'] = log['train_loss'].round(3)\n",
    "#log.index = log.epoch\n",
    "#del log['epoch']\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "ax.plot(log.epoch, log.train_f1, color=\"red\")\n",
    "ax.plot(log.epoch, log.val_f1, color=\"green\")\n",
    "\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"iterations\", fontsize = 14)\n",
    "\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"F1\", fontsize=14)\n",
    "\n",
    "ax.set_xticks(log.epoch.values)\n",
    "\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(log.epoch, log.train_loss,color=\"red\")\n",
    "ax2.plot(log.epoch, log.val_loss,color=\"green\")\n",
    "\n",
    "ax2.set_ylabel(\"LOSS\", fontsize=14)\n",
    "plt.grid(color = 'green', linestyle = '--', linewidth = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee45ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "#plt.plot(log.epoch, log.train_accuracy, label= 'train_accuracy')\n",
    "plt.plot(log.epoch, log.train_f1, label= 'train_f1')\n",
    "#plt.plot(log.epoch, log.val_accuracy, label= 'val_accuracy')\n",
    "plt.plot(log.epoch, log.val_f1, label='val_f1')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xticks(log.epoch, rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68fc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(log.epoch, log.train_loss, label='train_loss')\n",
    "plt.plot(log.epoch, log.val_loss, label='val_loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xticks(log.epoch, rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381939f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''EPOCH = 5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8,\n",
    "                  no_deprecation_warning=True)\n",
    "                  \n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=500,\n",
    "                                            num_training_steps=len(dataloader_train)*EPOCH)\n",
    "\n",
    "logs = []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    print('epoch--- ',epoch+1)\n",
    "    total_loss_train = 0\n",
    "    label_train =  torch.tensor([], dtype=torch.uint8).to(device)\n",
    "    pred_train = torch.tensor([], dtype=torch.uint8).to(device)\n",
    "\n",
    "    for train_input in tqdm(dataloader_train):\n",
    "        model.zero_grad()\n",
    "        input_id = train_input[0].to(device)\n",
    "        mask = train_input[1].to(device)\n",
    "        train_label = train_input[2].to(device)\n",
    "        output = model(input_id, mask)\n",
    "        label_train = torch.cat((label_train, train_label), 0)\n",
    "        batch_loss = criterion(output, train_label)\n",
    "        total_loss_train += batch_loss.item()\n",
    "        pred_train = torch.cat((pred_train, output.argmax(dim=1)), 0)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        #break\n",
    "    \n",
    "    label_train = label_train.detach().cpu().numpy()\n",
    "    pred_train = pred_train.detach().cpu().numpy()\n",
    "    total_acc_train = accuracy_score(label_train, pred_train)\n",
    "    total_f1_train = f1_score(label_train, pred_train, average='weighted')\n",
    "    total_loss_train = total_loss_train/(len(dataloader_train)*batch_size)\n",
    "\n",
    "    label_val =  torch.tensor([], dtype=torch.uint8).to(device)\n",
    "    pred_val = torch.tensor([], dtype=torch.uint8).to(device)\n",
    "    total_loss_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_input in tqdm(dataloader_validation):\n",
    "            input_id = val_input[0].to(device)\n",
    "            mask = val_input[1].to(device)\n",
    "            val_label = val_input[2].to(device)\n",
    "            output = model(input_id, mask)\n",
    "            label_val = torch.cat((label_val, val_label), 0)\n",
    "            batch_loss = criterion(output, val_label)\n",
    "            total_loss_val += batch_loss.item()\n",
    "            pred_val = torch.cat((pred_val, output.argmax(dim=1)), 0)\n",
    "            #break\n",
    "    \n",
    "    label_val = label_val.detach().cpu().numpy()\n",
    "    pred_val = pred_val.detach().cpu().numpy()\n",
    "    total_acc_val = accuracy_score(label_val, pred_val)\n",
    "    total_f1_val = f1_score(label_val, pred_val, average='weighted')\n",
    "    total_loss_val = total_loss_val/(len(dataloader_validation)*batch_size)\n",
    "    \n",
    "    torch.save(model.state_dict(), f'./model/BERT_encoder{HIDDEN_LAYER}_attention{ATTENTION}_epoch{epoch+1}.model')\n",
    "    \n",
    "    print('train_accuracy: ', total_acc_train, ', train_f1: ', total_f1_train, ', train_loss: ', total_loss_train)\n",
    "    print('val_accuracy: ', total_acc_val, ',  val_f1: ', total_f1_val, ', val_loss: ', total_loss_val)\n",
    "    print('\\n')\n",
    "    \n",
    "    logs.append({'epoch': epoch+1,\n",
    "                 'train_accuracy': total_acc_train,\n",
    "                 'train_f1': total_f1_train,\n",
    "                 'train_loss': total_loss_train,\n",
    "                 'val_accuracy': total_acc_val,\n",
    "                 'val_f1': total_f1_val,\n",
    "                 'val_loss': total_loss_val})'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c38db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5acf13",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133860e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['label'] = test.new_category.replace(label_dict)\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b08a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b4f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERTEncode(df, size, shuffle=False):\n",
    "    encoded_data = tokenizer.batch_encode_plus(\n",
    "        df.text.values, \n",
    "        add_special_tokens=True, \n",
    "        return_attention_mask=True, \n",
    "        padding='max_length', \n",
    "        max_length=512, \n",
    "        truncation=True,\n",
    "        return_tensors='pt')\n",
    "    input_ids = encoded_data['input_ids']\n",
    "    attention_masks = encoded_data['attention_mask']\n",
    "    labels = torch.tensor(df.label.values)\n",
    "    tensordataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    dataloader = DataLoader(tensordataset,\n",
    "                            shuffle=shuffle,\n",
    "                            num_workers=0,\n",
    "                            batch_size=size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac214b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "dataloader_test = BERTEncode(test, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31c1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTENTION = 12\n",
    "HIDDEN_LAYER = 1\n",
    "CLASSES = len(label_dict)\n",
    "\n",
    "model = BertClassifier(dropout=0.2, \n",
    "                       BERTconfig=True, \n",
    "                       attention_heads=ATTENTION,\n",
    "                       hidden_layers=HIDDEN_LAYER,\n",
    "                       numclass= CLASSES,\n",
    "                       hidden_dropout_prob=0.1,\n",
    "                       position_embedding_type='absolute')\n",
    "#model = BertClassifier(BERTconfig=False, numclass= CLASSES)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('/mnt/custommodel/BASE_BERT_encoder1_attention12_epoch7250.model', map_location=torch.device('cuda')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model):\n",
    "    actual =  torch.tensor([], dtype=torch.uint8).to(device)\n",
    "    predicted = torch.tensor([], dtype=torch.uint8).to(device)\n",
    "    cr = []\n",
    "\n",
    "    for input in tqdm(dataloader):\n",
    "        input_id = input[0].to(device)\n",
    "        mask = input[1].to(device)\n",
    "        labels = input[2].to(device)\n",
    "        actual = torch.cat((actual, labels), 0)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_id, mask)\n",
    "        predicted = torch.cat((predicted, output.argmax(dim=1)), 0)\n",
    "        for logits in output:\n",
    "            score = torch.nn.functional.softmax(logits, dim=0)\n",
    "            cr.append(np.float64(score.max(dim=0)[0].detach().cpu().numpy()))\n",
    "    \n",
    "    actual = actual.detach().cpu().numpy()\n",
    "    predicted = predicted.detach().cpu().numpy()\n",
    "    \n",
    "    total_acc_test = accuracy_score(actual, predicted)\n",
    "    total_f1_test = f1_score(actual, predicted, average='weighted')\n",
    "    print('Test Accuracy:', round(total_acc_test,2))\n",
    "    print('Test f1:', round(total_f1_test,2))\n",
    "    return (actual, predicted, cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad92fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, predicted, cr =validate(dataloader_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b32c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict_inv=dict()\n",
    "for label in label_dict:\n",
    "    label_dict_inv[label_dict[label]]=label\n",
    "label_dict_inv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c448026",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkfor = range(len(label_dict))\n",
    "#checkfor = [0]\n",
    "final_predicted = []\n",
    "    \n",
    "\n",
    "for check in checkfor:\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    notclassified = 0\n",
    "    score = []\n",
    "    for a,p, c in zip(actual, predicted, cr):\n",
    "             \n",
    "        if a == check:\n",
    "            total+=1\n",
    "            if (p == check):\n",
    "                correct+=1\n",
    "            elif (p!=check):\n",
    "                notclassified+=1\n",
    "                score.append(c)\n",
    "                \n",
    "    if total!=0:\n",
    "        acc = round(correct/total,2)\n",
    "        print('accuracy for {}: {}/{}={}'.format(label_dict_inv[check],correct,total,acc))\n",
    "        print('notclassified {}'.format(notclassified))\n",
    "        if notclassified!=0:\n",
    "            print('notclassified score for {}'.format(np.median(score)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215151b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['category']=='Mortgage Statement']['org/aug'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c32a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['category']=='Hazard Insurance Dec Page - Initial'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fdc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ocr=test[(test['category']=='Non-Mortgage Account Statement') &(test['ADR']=='ADR-2022-200000370062')]['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b8691",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ocr=''.join([i for i in test_ocr if not i.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35063091",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokens = tokenizer.tokenize(test_ocr)\n",
    "cnt=0\n",
    "for tup in zip(bert_tokens):\n",
    "    print('{:<12}'.format(tup[0]))\n",
    "    cnt+=1\n",
    "    if cnt>=512:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac6ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, encoded_data_text, labels, thresh):\n",
    "\n",
    "    input_ids_text = encoded_data_text['input_ids'].to(device)\n",
    "    attention_masks_text = encoded_data_text['attention_mask'].to(device)\n",
    "\n",
    "    with  torch.no_grad(): \n",
    "        outputs = model(input_ids_text, attention_masks_text)\n",
    "        \n",
    "    scores = torch.nn.functional.softmax(outputs.detach().cpu(), dim=1).numpy()[0]\n",
    "    \n",
    "    if np.max(scores)>thresh:\n",
    "        return (labels[np.argmax(scores)],np.max(scores))\n",
    "    else:\n",
    "        return ('others', np.max(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "txts=[test_ocr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "pred_label = []\n",
    "THRESHOLDS =0.9\n",
    "# for txt in global_validate['text'].values:\n",
    "for txt in txts:\n",
    "#for txt in zip(global_validate['text'].values, global_validate['Ref. No.'].values, global_validate['text'].values:\n",
    "    \n",
    "    encoded_data = tokenizer.encode_plus(\n",
    "            str(txt), \n",
    "            add_special_tokens=True, \n",
    "            return_attention_mask=True, \n",
    "            padding='max_length', \n",
    "            max_length=512, \n",
    "            truncation=True,\n",
    "            return_tensors='pt')\n",
    "\n",
    "    predictions=predict(model,encoded_data,label_dict_inv,THRESHOLDS)\n",
    "#     with ThreadPoolExecutor() as executor:\n",
    "#         predictions = executor.map(predict, BERT_MODELS, [encoded_data]*len(labels), labels, THRESHOLDS)\n",
    "    predictions = list(predictions)\n",
    "#     print(predictions)\n",
    "#     if(predictions[0][0]=='focused'):\n",
    "#         classifications = list(filter(lambda x: x[0]!='others', predictions[1:]))\n",
    "#         if len(classifications)==0:\n",
    "#             final_class = sorted(predictions[1:],key=lambda x: x[1], reverse=True)[0]\n",
    "#         else:\n",
    "#             final_class = sorted(classifications,key=lambda x: x[1], reverse=True)[0]\n",
    "\n",
    "#         '''if final_class[1]>0.90:\n",
    "#             final_class = final_class\n",
    "#         else:\n",
    "#             final_class = ('others',final_class[1])'''\n",
    "#     else:\n",
    "#         final_class = ('others',predictions[0][1])\n",
    "#     pred_label.append(label[final_class[0]])\n",
    "    print(predictions)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b8c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e7747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc46e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c6acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41404102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a6b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184d39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e77ac89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1256c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cb75ec7",
   "metadata": {},
   "source": [
    "### GLOBAL_VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d270e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_validate = pd.read_csv('./global_validate.csv')\n",
    "global_validate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744cce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_validate = global_validate[global_validate['new_text_format']=='new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea29ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_validate.drop(global_validate[global_validate['category']=='Tax Return'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "index=[]\n",
    "for i,row in global_validate.iterrows():\n",
    "    if row['ADR'] in data['ADR'].values.tolist():\n",
    "        if row['text'] in data['text'][data['ADR']==row['ADR']].values.tolist():\n",
    "            count+=1\n",
    "            index.append(i)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6430ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del global_validate['new_category']\n",
    "#global_validate.drop(index=index, inplace=True)\n",
    "global_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c187e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_validate['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate.to_csv('./global_validate.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "cats = ['Tax Return - Personal', \n",
    "        'Tax Return - Business', \n",
    "        'K1s',\n",
    "        'Retirement Account Statement(s)',\n",
    "        'Mortgage Statement',\n",
    "        'Bank Statement',\n",
    "        'Purchase Agreement',\n",
    "        'Rental Agreements(s)',\n",
    "        'Hazard Insurance Dec Page - Initial',\n",
    "        'Divorce Decree / Child Support',\n",
    "        'Bankruptcy Papers']\n",
    "\n",
    "# cats = ['Retirement Account Statement(s)', \n",
    "#         'Mortgage Statement',\n",
    "#         'Bank Statement']\n",
    "\n",
    "for category in global_validate['category']:\n",
    "    if category not in cats:\n",
    "        temp.append('others')\n",
    "    else:\n",
    "        temp.append('focused')\n",
    "global_validate['new_category'] = temp\n",
    "global_validate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['label'] = global_validate.new_category.replace(label_dict)\n",
    "global_validate.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['text']= [str(text) for text in global_validate['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c423606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERTEncode(df, size, shuffle=False):\n",
    "    encoded_data = tokenizer.batch_encode_plus(\n",
    "        df['new_format_text'].values, \n",
    "        add_special_tokens=True, \n",
    "        return_attention_mask=True, \n",
    "        padding='max_length', \n",
    "        max_length=512, \n",
    "        truncation=True,\n",
    "        return_tensors='pt')\n",
    "    input_ids = encoded_data['input_ids']\n",
    "    attention_masks = encoded_data['attention_mask']\n",
    "    labels = torch.tensor(df.label.values)\n",
    "    tensordataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    dataloader = DataLoader(tensordataset,\n",
    "                            shuffle=shuffle,\n",
    "                            num_workers=0,\n",
    "                            batch_size=size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c202ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = BERTEncode(global_validate, 32, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47de2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dc2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTENTION = 12\n",
    "HIDDEN_LAYER = 1\n",
    "CLASSES = len(label_dict)\n",
    "\n",
    "\n",
    "model = BertClassifier(dropout=0.2, \n",
    "                       BERTconfig=True, \n",
    "                       attention_heads=ATTENTION,\n",
    "                       hidden_layers=HIDDEN_LAYER,\n",
    "                       numclass= CLASSES,\n",
    "                       hidden_dropout_prob=0.1,\n",
    "                       position_embedding_type='absolute')\n",
    "\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('/mnt/model/BERT_encoder1_attention12_epoch3000.model', map_location=torch.device('cuda')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68830f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, predicted, cr = validate(dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f5d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict_inv=dict()\n",
    "for label in label_dict:\n",
    "    label_dict_inv[label_dict[label]]=label\n",
    "label_dict_inv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd5da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6901f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshholds = range(0,92,2)\n",
    "checkfor = range(len(label_dict))\n",
    "\n",
    "accuracy=[]\n",
    "notclassified = []\n",
    "for thresh in threshholds:\n",
    "    \n",
    "    final_predicted=[]\n",
    "    for a,p,c in zip(actual, predicted, cr):\n",
    "        if c>(thresh/100):\n",
    "            final_predicted.append(p)\n",
    "        else:\n",
    "            final_predicted.append(0)\n",
    "    \n",
    "    acc = 0\n",
    "    incorrect = 0\n",
    "    for check in checkfor:\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for a,p,c in zip(actual, final_predicted, cr):\n",
    "            if a == check:\n",
    "                total+=1\n",
    "                if (p == check):\n",
    "                    correct+=1\n",
    "                elif (p!=check):\n",
    "                    incorrect+=1\n",
    "        if(total!=0):\n",
    "            acc = acc+round(correct/total,2)\n",
    "    #accuracy.append(acc/len(checkfor))\n",
    "    accuracy.append(acc/len(global_validate['new_category'].unique()))\n",
    "    notclassified.append(incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "ax.plot(threshholds,\n",
    "        accuracy,\n",
    "        color=\"red\", \n",
    "        marker=\"o\")\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"threshold\", fontsize = 14)\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"accuracy\",\n",
    "              color=\"red\",\n",
    "              fontsize=14)\n",
    "\n",
    "ax.set_xticks(list(threshholds))\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(threshholds, notclassified,color=\"blue\",marker=\"o\")\n",
    "ax2.set_ylabel(\"notclassified\",color=\"blue\",fontsize=14)\n",
    "plt.grid(color = 'green', linestyle = '--', linewidth = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc87cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkfor = range(len(label_dict))\n",
    "#checkfor = [0]\n",
    "final_predicted = []\n",
    "\n",
    "for a,p, c in zip(actual, predicted, cr):\n",
    "    if c>0.90:\n",
    "        final_predicted.append(p)\n",
    "    else:\n",
    "        final_predicted.append(0)\n",
    "    \n",
    "\n",
    "for check in checkfor:\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    notclassified = 0\n",
    "    score = []\n",
    "    for a,p, c in zip(actual, final_predicted, cr):\n",
    "             \n",
    "        if a == check:\n",
    "            total+=1\n",
    "            if (p == check):\n",
    "                correct+=1\n",
    "            #elif ((p!=check)&(c<0.90)):\n",
    "            #    correct+=1\n",
    "            #elif ((p!=check)&(c>0.90)):\n",
    "            #    notclassified+=1\n",
    "            elif (p!=check):\n",
    "                notclassified+=1\n",
    "                score.append(c)\n",
    "                \n",
    "    if total!=0:\n",
    "        acc = round(correct/total,2)\n",
    "        print('accuracy for {}: {}/{}={}'.format(label_dict_inv[check],correct,total,acc))\n",
    "        print('notclassified {}'.format(notclassified))\n",
    "        if notclassified!=0:\n",
    "            print('notclassified score for {}'.format(np.median(score)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['predlabel'] = list(final_predicted)\n",
    "global_validate['predicted'] = [label_dict_inv[i] for i in final_predicted]\n",
    "global_validate['cr'] = list(cr)\n",
    "#global_validate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['category'][(global_validate['new_category']=='others')&\n",
    "                            (global_validate['predicted']!='others')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1fdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca68654",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate[(global_validate['label']==0)&(global_validate['predlabel']!=0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c67c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e310f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da9f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f066eab",
   "metadata": {},
   "source": [
    "### after deployment validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_validate = pd.read_csv('./global_validate.csv')\n",
    "global_validate = pd.read_csv(\"BERT Testing_28.07.2022.csv\")\n",
    "global_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f78355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25536c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['Actual Classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c5797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count=0\n",
    "# index=[]\n",
    "# for i,adr in enumerate(global_validate['ADR']):\n",
    "#     if adr in data['ADR'].values.tolist():\n",
    "#         count+=1\n",
    "#         index.append(i)\n",
    "# global_validate.drop(index=index, inplace=True)\n",
    "# global_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce20211",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {\n",
    "    'others': 0,\n",
    "    'Retirement Account Statement(s)': 1, \n",
    "    'Mortgage Statement': 2, \n",
    "    'Bank Statement': 3, \n",
    "    'Purchase Agreement': 4, \n",
    "    'Rental Agreements(s)': 5,\n",
    "    'Divorce Decree / Child Support': 6,\n",
    "    'Hazard Insurance Dec Page - Initial': 7,\n",
    "    'Bankruptcy Papers': 8,\n",
    "    'Tax Return - Personal': 9, \n",
    "    'Tax Return - Business': 10, \n",
    "    'K1s':11\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_inv=dict()\n",
    "for lab in label:\n",
    "    label_inv[label[lab]]=lab\n",
    "label_inv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14baaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "\n",
    "cats = list(label.keys())\n",
    "\n",
    "for category in global_validate['Actual Classification']:\n",
    "    if category not in cats:\n",
    "        temp.append('others')\n",
    "    else:\n",
    "        temp.append(category)\n",
    "global_validate['new_category'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc6335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['label'] = global_validate.new_category.replace(label)\n",
    "global_validate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b316478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49379949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 dropout=0.1, \n",
    "                 BERTconfig=False, \n",
    "                 attention_heads=12, \n",
    "                 hidden_layers=12, \n",
    "                 numclass=1,\n",
    "                 hidden_dropout_prob=0.1,\n",
    "                 hidden_act='gelu',\n",
    "                 position_embedding_type='absolute'):\n",
    "        \n",
    "        #self.attention_heads = attention_heads\n",
    "        super(BertClassifier, self).__init__()\n",
    "        \n",
    "        if BERTconfig:\n",
    "            configuration = BertConfig(num_attention_heads= attention_heads, \n",
    "                                       num_hidden_layers= hidden_layers)   \n",
    "        else:\n",
    "            configuration = BertConfig()\n",
    "        #self.bert = BertModel.from_pretrained('bert-base-uncased', output_attentions=attention)\n",
    "        #print(configuration)\n",
    "        self.bert = BertModel(configuration)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, numclass, bias=True)\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c753bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import ast\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "configs = configparser.ConfigParser()\n",
    "configs.read('./config.ini')\n",
    "labels = []\n",
    "BERT_MODELS = []\n",
    "THRESHOLDS=[]\n",
    "\n",
    "for config in configs.sections():\n",
    "    label_ = ast.literal_eval(configs[config].get('categoryMAP'))\n",
    "    labels.append(label_)\n",
    "    THRESHOLDS.append(float(configs[config].get('cr_thresh')))\n",
    "    \n",
    "    HIDDEN_LAYERS = int(configs[config].get('hidden_layers'))\n",
    "    ATTENTIONS = int(configs[config].get('attentions'))\n",
    "    CLASSES = len(label_)\n",
    "    MODEL_FOLDER = configs[config].get('modelfolder')\n",
    "    model = BertClassifier(BERTconfig=True, attention_heads=ATTENTIONS, hidden_layers=HIDDEN_LAYERS, numclass= CLASSES)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load('./model/{}/BERT.model'.format(MODEL_FOLDER), map_location=torch.device('cuda')))\n",
    "    model.eval()\n",
    "    BERT_MODELS.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c82a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, encoded_data_text, labels, thresh):\n",
    "\n",
    "    input_ids_text = encoded_data_text['input_ids'].to(device)\n",
    "    attention_masks_text = encoded_data_text['attention_mask'].to(device)\n",
    "\n",
    "    with  torch.no_grad(): \n",
    "        outputs = model(input_ids_text, attention_masks_text)\n",
    "        \n",
    "    scores = torch.nn.functional.softmax(outputs.detach().cpu(), dim=1).numpy()[0]\n",
    "    \n",
    "    if np.max(scores)>thresh:\n",
    "        return (labels[np.argmax(scores)],np.max(scores))\n",
    "    else:\n",
    "        return ('others', np.max(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fee5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = ['J.P.Morgan BRANDON R LIPMAN IRA Statement Period: April 01 - April 29, 2022 JPMS LLC IRA (Acct # 988-32917) JPMS LLC CUST. J.P. Morgan Self-Directed Investing Activity CASH FLOW SUMMARY This Period Year-to-Date Description $937.43 $937.40 Opening Cash Balance 0.01 0.04 Income $0.01 $0.04 Total Credits $0.00 0.00 Total Debits Net Cash Activity $0.01 $0.04 CLOSING CASH BALANCE $937.44 $937.44 \"Opening Cash Balance\" and \"Closing Cash Balance\" include Sweep Funds. SWEEP PROGRAM ACTIVITY CHASE IRA DEPOSIT SWEEP,JPMORGAN CHASE BANK NA, Symbol: QDERQ Debit Amount Credit Amount Transaction Description Quantity Price Date 937.43 OPENING BALANCE (0.01) MONTHLY INTEREST 0.01 01 Apr 2022 REINVEST REINVESTED 937.44 1 CLOSING BALANCE CHASE IRA DEPOSIT SWEEP,JPMORGAN CHASE BANK NA, Symbol: QDERQ Credit Amount Description Quantity Price Debit Amount Date Transaction 0.01 INTEREST MONTHLY INTEREST 01 Apr 2022 03/01-03/31 ($0.01) SWEEP PROGRAM ACTIVITY $0.01 Sweep Program Dividend/Interest ($0.01) Total Sweep Program Activity A - Average Cost B-Adjusted for Amortization or Accretion D - Acquisition Date = Date of Death E- Adjusted for Option Exercise or Assignment K- Gifted Security LT - Long Term MT - Mixed Term N-Noncovered Provide - Please provide this information ST - Short Term T- Cost Basis provided by Third Party W- Adjusted for Wash Sale Closing Methods: MLMG - Maximum Loss, Minimum Gain LIFO- Last In, First Out FIFO - First In, First Out HC-High Cost LC-Low Cost LTHC-Long Term, High Cost PRO - Pro Rata VSP - Specific Match (the closing transaction was specifically matched to this lot) Page 8 of 14 Please read the important disclosures at the end of the statement. For questions, please contact us using the information provided on the front of this statement. IMPORTANT INFORMATION STATEMENT SUMMARY RETIREMENT BROKERAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "pred_label = []\n",
    "\n",
    "# for txt in global_validate['text'].values:\n",
    "for txt in txts:\n",
    "#for txt in zip(global_validate['text'].values, global_validate['Ref. No.'].values, global_validate['text'].values:\n",
    "    \n",
    "    encoded_data = tokenizer.encode_plus(\n",
    "            str(txt), \n",
    "            add_special_tokens=True, \n",
    "            return_attention_mask=True, \n",
    "            padding='max_length', \n",
    "            max_length=512, \n",
    "            truncation=True,\n",
    "            return_tensors='pt')\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        predictions = executor.map(predict, BERT_MODELS, [encoded_data]*len(labels), labels, THRESHOLDS)\n",
    "    predictions = list(predictions)\n",
    "    print(predictions)\n",
    "    if(predictions[0][0]=='focused'):\n",
    "        classifications = list(filter(lambda x: x[0]!='others', predictions[1:]))\n",
    "        if len(classifications)==0:\n",
    "            final_class = sorted(predictions[1:],key=lambda x: x[1], reverse=True)[0]\n",
    "        else:\n",
    "            final_class = sorted(classifications,key=lambda x: x[1], reverse=True)[0]\n",
    "\n",
    "        '''if final_class[1]>0.90:\n",
    "            final_class = final_class\n",
    "        else:\n",
    "            final_class = ('others',final_class[1])'''\n",
    "    else:\n",
    "        final_class = ('others',predictions[0][1])\n",
    "    pred_label.append(label[final_class[0]])\n",
    "    print(final_class)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32466001",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(global_validate['label'].values, np.array(pred_label))\n",
    "f1 = f1_score(global_validate['label'].values, np.array(pred_label), average='weighted')\n",
    "acc,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b0d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cadc621",
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(label_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkfor = range(len(label_inv))\n",
    "for check in checkfor:\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    notclassified = 0\n",
    "    score = []\n",
    "    for a,p in zip(global_validate['label'].values, np.array(pred_label)):\n",
    "             \n",
    "        if a == check:\n",
    "            total+=1\n",
    "            if (p == check):\n",
    "                correct+=1\n",
    "            elif (p!=check):\n",
    "                notclassified+=1\n",
    "                \n",
    "    if total!=0:\n",
    "        acc = round(correct/total,2)\n",
    "        print('accuracy for {}: {}/{}={}'.format(label_inv[check],correct,total,acc))\n",
    "        #print('notclassified {}'.format(notclassified))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17972034",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['pred_label'] = pred_label\n",
    "global_validate.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['pred_category'] = global_validate['pred_label'].replace(label_inv )\n",
    "global_validate.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['new_category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43795201",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i,j in zip(global_validate['new_category'].values, global_validate['pred_category'].values):\n",
    "    if i==j:\n",
    "        temp.append('PASS')\n",
    "    else:\n",
    "        temp.append('FAIL')\n",
    "global_validate['local_P/F']= temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e1298",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate.to_csv('./valid.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb837451",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate[(global_validate['label']==0)&\n",
    "                            (global_validate['pred_label']!=0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea93914",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank \n",
    "morgage \n",
    "Retirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Purchase\n",
    "Rental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8705aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax return\n",
    "k1\n",
    "w2\n",
    "paystub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1747b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147fadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.char as nac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257eade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "augc= nac.OcrAug() \n",
    "'''aug = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', \n",
    "                                model_type='bert',\n",
    "                                action=\"insert\", \n",
    "                                aug_p=0.80)'''\n",
    "                                \n",
    "#augs = nas.ContextualWordEmbsForSentenceAug(model_path='gpt2', top_p=0.5, batch_size=4)\n",
    "#randomSentAug = nas.random.RandomSentAug(mode='neighbor', action='swap') <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e213ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [data['text'][1],data['text'][0]]\n",
    "augmented_data = augc.augment(txt)\n",
    "#augmented_data = randomWordAug.augment(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff0dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec9720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c8d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f1f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification_service",
   "language": "python",
   "name": "classification_service"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

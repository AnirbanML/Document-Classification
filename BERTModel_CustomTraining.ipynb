{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9cc54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertModel\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import json\n",
    "import random\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0fe4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 3000\n",
    "pd.options.display.max_rows = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c776098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c436419b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146435, 12)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_csv('./Backup master data/master_data_6.csv', usecols=['ADR', 'text', 'category', 'type', 'date'])\n",
    "# data = pd.read_csv('./oldnew.csv')\n",
    "# data = pd.read_csv('/data/mmortgage/amal_workspace/multipageAccuracy/data/raw/master_data_V3_0_19Sept22.csv')\n",
    "data = pd.read_csv('/data/mmortgage/amal_workspace/multipageAccuracy/data/processed/master_data_V3_0_20Sept22_processed_sampledc1.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de5ac351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LD      116631\n",
       "NMIC     29804\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b55b6909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADR                     0\n",
       "text                    0\n",
       "category                0\n",
       "type                    0\n",
       "date                    0\n",
       "ogr/aug                 0\n",
       "page#                   0\n",
       "angle                   0\n",
       "renamed category    68381\n",
       "text_processed          0\n",
       "word_count              0\n",
       "category_new            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19d4f28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146435, 12)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(subset=['text'], inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bd647dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bank Statement                                        16392\n",
       "Tax Return - Business                                 15794\n",
       "Purchase Agreement                                    15150\n",
       "Tax Return - Personal                                 13349\n",
       "Paystub                                               13033\n",
       "Hazard Insurance Dec Page - Initial                   12688\n",
       "Retirement Account Statement(s)                       10958\n",
       "W-2(s) / 1099(s)                                       6539\n",
       "Condominium Documents                                  5730\n",
       "Rental Agreements(s)                                   5268\n",
       "Mortgage Statement                                     5043\n",
       "Driver's License                                       3475\n",
       "Divorce Decree / Child Support                         3292\n",
       "Title Report                                           3158\n",
       "Divorce Decree                                         2806\n",
       "Escrow/Closing Instructions                            1993\n",
       "K1s                                                    1670\n",
       "Award Letter(s)                                        1363\n",
       "Letter of Explanation                                  1269\n",
       "Bankruptcy Papers                                       956\n",
       "NOTE with all Attachments                               859\n",
       "Social Security Award Letter                            650\n",
       "Non-Mortgage Statement                                  572\n",
       "Setup Submission Form                                   563\n",
       "Due Diligence Report                                    547\n",
       "Credit Report                                           453\n",
       "Escrow / Closing Instructions                           389\n",
       "Trust Certification                                     373\n",
       "SSN Card                                                347\n",
       "Disclosures                                             321\n",
       "Earnest Money Deposit                                   251\n",
       "Permanent Resident Card                                 213\n",
       "Misc Closing Disclosures                                209\n",
       "VA - DD214 Member Copy for Discharge                    122\n",
       "IRS Transcripts                                         118\n",
       "Passport/Green Card                                     118\n",
       "1003                                                     77\n",
       "Tax Returns                                              60\n",
       "Income - Other                                           50\n",
       "Others                                                   41\n",
       "Lender Approval                                          38\n",
       "4506-C                                                   37\n",
       "Flood Certificate                                        23\n",
       "Appraisal - Appraisal Report                             17\n",
       "Other                                                    15\n",
       "4506-T                                                   13\n",
       "W-9                                                      11\n",
       "DU Findings                                               3\n",
       "Condo/Coop/HOA                                            3\n",
       "Identification                                            3\n",
       "Verification of business (VOB)/SOS Business Search        2\n",
       "Property - Other                                          2\n",
       "Title - Other                                             2\n",
       "Gift Letter                                               1\n",
       "Business License                                          1\n",
       "LP Findings                                               1\n",
       "Closing Disclosure                                        1\n",
       "Appraisal â€“ Other                                         1\n",
       "Profit & Loss(s)                                          1\n",
       "4506C Results                                             1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2685d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = data[data['category']=='Bank Statement'].index.tolist()\n",
    "# data.drop(index= random.sample(n, 10000), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe4595d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71fb949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {'Assets - Source of funds': 'Bank Statement',\n",
    " 'Bank Statement': 'Bank Statement',\n",
    " 'Bank Statement(s)': 'Bank Statement',\n",
    " 'BK Papers': 'Bankruptcy Papers',\n",
    " 'Child Support/Alimony Agreement': 'Divorce Decree / Child Support',\n",
    " 'Construction Agreement/Contract': 'Purchase Agreement',\n",
    " 'Contractor Bids': 'Purchase Agreement',\n",
    " 'Contractor Docs': 'Purchase Agreement',\n",
    " 'Escrow/Closing Instructions' : 'Escrow / Closing Instructions',\n",
    " 'Divorce Decree': 'Divorce Decree / Child Support',\n",
    " 'Earnest Money Deposit': 'Purchase Agreement',\n",
    " 'Gift Funds': 'Bank Statement',\n",
    " 'Hazard Insurance Contact Information': 'Hazard Insurance',\n",
    " 'Hazard Insurance Dec Page - Final': 'Hazard Insurance',\n",
    " 'Hazard Insurance Dec Page - Incomplete': 'Hazard Insurance',\n",
    " 'Hazard Insurance Dec Page - Initial': 'Hazard Insurance',\n",
    " 'Hazard Insurance Dec Page - Insufficient Coverage': 'Hazard Insurance',\n",
    " 'Hazard Insurance Declaration': 'Hazard Insurance',\n",
    " 'Insurance - Cost Estimator': 'Hazard Insurance',\n",
    " 'Insurance - Hazard Checklist': 'Hazard Insurance',\n",
    " 'Insurance - Proof Paid': 'Hazard Insurance',\n",
    " 'Insurance Dec Page, Other': 'Hazard Insurance',\n",
    " 'Insurance Document - Other': 'Hazard Insurance',\n",
    " 'Investment Account Statements': 'Retirement Account Statement(s)',\n",
    " 'Mortgage Statement': 'Mortgage Statement',\n",
    " 'Mortgage Statement of Inspection of Subject Property': 'Mortgage Statement',\n",
    " 'Mortgage Statement/Coupon, 1st': 'Mortgage Statement',\n",
    " 'Mortgage Statement/Coupon, 2nd': 'Mortgage Statement',\n",
    " 'Other Property 1st Mtg Stmt': 'Mortgage Statement',\n",
    " 'Other Property 2nd Mtg Stmt': 'Mortgage Statement',\n",
    " 'Purchase Agreement': 'Purchase Agreement',\n",
    " 'Purchase Agreement Addendum': 'Purchase Agreement',\n",
    " 'Purchase Document Other': 'Purchase Agreement',\n",
    " 'Rental Agreements(s)': 'Rental Agreements(s)',\n",
    " 'Retirement Account Statement(s)': 'Retirement Account Statement(s)',\n",
    " 'Sales Checklist': 'Purchase Agreement',\n",
    " 'Sales Contract and Addendums': 'Purchase Agreement',\n",
    " 'Sales Contract/Purchase Agreement': 'Purchase Agreement',\n",
    " 'Sales Forms': 'Purchase Agreement',\n",
    " 'Sales Stips': 'Purchase Agreement',\n",
    " 'Divorce Decree / Child Support': 'Divorce Decree / Child Support',\n",
    " \"Non-Mortgage Account Statement\" : \"Non-Mortgage Statement\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c4d0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category'] = data['category'].replace(mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89581c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bank Statement                                        16392\n",
       "Tax Return - Business                                 15794\n",
       "Purchase Agreement                                    15401\n",
       "Tax Return - Personal                                 13349\n",
       "Paystub                                               13033\n",
       "Hazard Insurance                                      12688\n",
       "Retirement Account Statement(s)                       10958\n",
       "W-2(s) / 1099(s)                                       6539\n",
       "Divorce Decree / Child Support                         6098\n",
       "Condominium Documents                                  5730\n",
       "Rental Agreements(s)                                   5268\n",
       "Mortgage Statement                                     5043\n",
       "Driver's License                                       3475\n",
       "Title Report                                           3158\n",
       "Escrow / Closing Instructions                          2382\n",
       "K1s                                                    1670\n",
       "Award Letter(s)                                        1363\n",
       "Letter of Explanation                                  1269\n",
       "Bankruptcy Papers                                       956\n",
       "NOTE with all Attachments                               859\n",
       "Social Security Award Letter                            650\n",
       "Non-Mortgage Statement                                  572\n",
       "Setup Submission Form                                   563\n",
       "Due Diligence Report                                    547\n",
       "Credit Report                                           453\n",
       "Trust Certification                                     373\n",
       "SSN Card                                                347\n",
       "Disclosures                                             321\n",
       "Permanent Resident Card                                 213\n",
       "Misc Closing Disclosures                                209\n",
       "VA - DD214 Member Copy for Discharge                    122\n",
       "Passport/Green Card                                     118\n",
       "IRS Transcripts                                         118\n",
       "1003                                                     77\n",
       "Tax Returns                                              60\n",
       "Income - Other                                           50\n",
       "Others                                                   41\n",
       "Lender Approval                                          38\n",
       "4506-C                                                   37\n",
       "Flood Certificate                                        23\n",
       "Appraisal - Appraisal Report                             17\n",
       "Other                                                    15\n",
       "4506-T                                                   13\n",
       "W-9                                                      11\n",
       "DU Findings                                               3\n",
       "Condo/Coop/HOA                                            3\n",
       "Identification                                            3\n",
       "Verification of business (VOB)/SOS Business Search        2\n",
       "Property - Other                                          2\n",
       "Title - Other                                             2\n",
       "Gift Letter                                               1\n",
       "Appraisal â€“ Other                                         1\n",
       "LP Findings                                               1\n",
       "Closing Disclosure                                        1\n",
       "Profit & Loss(s)                                          1\n",
       "Business License                                          1\n",
       "4506C Results                                             1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b46ae",
   "metadata": {},
   "source": [
    "### Stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2370640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alterted_text=[]\n",
    "# remove_words = set(stopwords.words('english') + list(string.punctuation))\n",
    "# for text in data.text.values:\n",
    "#     text = re.sub(r'[~^0-9]', '', text)\n",
    "#     wordlist = [word for word in word_tokenize(text.lower()) if not word in remove_words]\n",
    "#     alterted_text.append((\" \").join(wordlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8f345c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['text']= alterted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef3f45",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8174695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "\n",
    "cats = ['Retirement Account Statement(s)',\n",
    "        'Mortgage Statement',\n",
    "        'Bank Statement',\n",
    "        'Non-Mortgage Statement',\n",
    "        'Due Diligence Report',\n",
    "        'Purchase Agreement',\n",
    "        'Rental Agreements(s)',\n",
    "        'Hazard Insurance',\n",
    "        'Divorce Decree / Child Support',\n",
    "        'Bankruptcy Papers']\n",
    "\n",
    "# cats = ['Retirement Account Statement(s)',\n",
    "#         'Mortgage Statement',\n",
    "#         'Bank Statement',\n",
    "#         'Non-Mortgage Statement']\n",
    "\n",
    "        \n",
    "        \n",
    "for category in data['category']:\n",
    "    if category not in cats:\n",
    "        temp.append('others')\n",
    "    else:\n",
    "        temp.append(\"focused\")\n",
    "data['new_category'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85f68831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['others', 'focused'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['new_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "785bbbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'focused': 1, 'others0': 0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "label_dict['focused'] = 1\n",
    "label_dict['others0'] = 0\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74388380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible_labels = data.new_category.unique()\n",
    "\n",
    "# label_dict = {}\n",
    "# label_dict['others']=0\n",
    "# for i,cat in enumerate(cats):\n",
    "#     label_dict[cat]=i+1\n",
    "# label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c784460",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data.new_category.replace(label_dict)\n",
    "# data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e0d7d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117148, 14)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.sample(frac=0.80, random_state=200)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3543c958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bank Statement                                        13083\n",
       "Tax Return - Business                                 12638\n",
       "Purchase Agreement                                    12257\n",
       "Tax Return - Personal                                 10741\n",
       "Paystub                                               10475\n",
       "Hazard Insurance                                      10115\n",
       "Retirement Account Statement(s)                        8714\n",
       "W-2(s) / 1099(s)                                       5260\n",
       "Divorce Decree / Child Support                         4918\n",
       "Condominium Documents                                  4605\n",
       "Rental Agreements(s)                                   4235\n",
       "Mortgage Statement                                     4016\n",
       "Driver's License                                       2809\n",
       "Title Report                                           2509\n",
       "Escrow / Closing Instructions                          1907\n",
       "K1s                                                    1337\n",
       "Award Letter(s)                                        1111\n",
       "Letter of Explanation                                  1018\n",
       "Bankruptcy Papers                                       743\n",
       "NOTE with all Attachments                               681\n",
       "Social Security Award Letter                            511\n",
       "Non-Mortgage Statement                                  462\n",
       "Due Diligence Report                                    443\n",
       "Setup Submission Form                                   436\n",
       "Credit Report                                           347\n",
       "Trust Certification                                     300\n",
       "SSN Card                                                285\n",
       "Disclosures                                             268\n",
       "Misc Closing Disclosures                                172\n",
       "Permanent Resident Card                                 164\n",
       "VA - DD214 Member Copy for Discharge                     94\n",
       "Passport/Green Card                                      93\n",
       "IRS Transcripts                                          88\n",
       "1003                                                     68\n",
       "Tax Returns                                              43\n",
       "Income - Other                                           37\n",
       "Others                                                   32\n",
       "4506-C                                                   30\n",
       "Lender Approval                                          26\n",
       "Flood Certificate                                        15\n",
       "Other                                                    13\n",
       "Appraisal - Appraisal Report                             12\n",
       "4506-T                                                   11\n",
       "W-9                                                       8\n",
       "Condo/Coop/HOA                                            3\n",
       "Title - Other                                             2\n",
       "Property - Other                                          2\n",
       "Identification                                            2\n",
       "Gift Letter                                               1\n",
       "Closing Disclosure                                        1\n",
       "Business License                                          1\n",
       "Appraisal â€“ Other                                         1\n",
       "Verification of business (VOB)/SOS Business Search        1\n",
       "4506C Results                                             1\n",
       "Profit & Loss(s)                                          1\n",
       "LP Findings                                               1\n",
       "DU Findings                                               1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6efd3751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29287, 14)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data.drop(df.index).reset_index(drop=True)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60cdeb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"/data/mmortgage/amal_workspace/multipageAccuracy/data/train dataset/train_set_20_SEPT_2022.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97770f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "focused    14937\n",
       "others     14350\n",
       "Name: new_category, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e8803e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "focused    58986\n",
       "others     58162\n",
       "Name: new_category, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_category'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de814859",
   "metadata": {},
   "outputs": [],
   "source": [
    "classweight = torch.tensor(class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                             classes=df['new_category'].unique().tolist(),\n",
    "                                                             y=df['new_category'].values.tolist()), dtype=torch.float)\n",
    "classweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21062e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "# df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c25afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7186a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_type'] = 'not_set'\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c62fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b2f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['new_category', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c776d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./bert-base-uncased-customizedtokens')\n",
    "# '../amal_workspace/multipageAccuracy/bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b0abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].text_processed.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=512, \n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].text_processed.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277dad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ad2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59692c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              shuffle=True,\n",
    "                              num_workers=0, \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   shuffle=False,\n",
    "                                   num_workers=0, \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c6a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ed309",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader_train)*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f436f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 dropout=0.1, \n",
    "                 BERTconfig=False, \n",
    "                 attention_heads=12, \n",
    "                 hidden_layers=12, \n",
    "                 numclass=1,\n",
    "                 hidden_dropout_prob=0.1,\n",
    "                 hidden_act='gelu',\n",
    "                 position_embedding_type='absolute'):\n",
    "        \n",
    "        #self.attention_heads = attention_heads\n",
    "        super(BertClassifier, self).__init__()\n",
    "        \n",
    "        if BERTconfig:\n",
    "            configuration = BertConfig(num_attention_heads= attention_heads, \n",
    "                                       num_hidden_layers= hidden_layers)   \n",
    "        else:\n",
    "            configuration = BertConfig()\n",
    "        #self.bert = BertModel.from_pretrained('bert-base-uncased', output_attentions=attention)\n",
    "        #print(configuration)\n",
    "        self.bert = BertModel(configuration)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, numclass, bias=True)\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c86f4858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'focused': 1, 'others0': 0}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a21c832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATTENTION = 12\n",
    "HIDDEN_LAYER = 1\n",
    "CLASSES = len(label_dict)\n",
    "\n",
    "\n",
    "model = BertClassifier(dropout=0.3, \n",
    "                       BERTconfig=True, \n",
    "                       attention_heads=ATTENTION,\n",
    "                       hidden_layers=HIDDEN_LAYER,\n",
    "                       numclass= CLASSES,\n",
    "                       hidden_dropout_prob=0.3,\n",
    "                       position_embedding_type='absolute')\n",
    "\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 2\n",
    "\n",
    "save_model = 250\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=classweight.to(device), reduction='mean')\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8,\n",
    "                  no_deprecation_warning=True)\n",
    "                  \n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=250,\n",
    "                                            num_training_steps=len(dataloader_train)*EPOCH)\n",
    "\n",
    "\n",
    "logs = []\n",
    "i=0\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    print('epoch--- ',epoch+1)\n",
    "    \n",
    "    for train_input in tqdm(dataloader_train):\n",
    "        i=i+1\n",
    "        model.zero_grad()\n",
    "        input_id = train_input[0].to(device)\n",
    "        mask = train_input[1].to(device)\n",
    "        train_label = train_input[2].to(device)\n",
    "        output = model(input_id, mask)\n",
    "        batch_loss = criterion(output, train_label)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if(i%save_model==0):\n",
    "            label_train =  torch.tensor([]).to(device)\n",
    "            pred_train = torch.tensor([]).to(device)\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_eval in dataloader_train:\n",
    "                input_id = train_eval[0].to(device)\n",
    "                mask = train_eval[1].to(device)\n",
    "                train_label = train_eval[2].to(device)\n",
    "                output = model(input_id, mask)\n",
    "                batch_loss = criterion(output, train_label)\n",
    "                total_loss_train += batch_loss.item()\n",
    "                label_train = torch.cat((label_train, train_label), 0)\n",
    "                pred_train = torch.cat((pred_train, output.argmax(dim=1)), 0)\n",
    "            \n",
    "            label_train = label_train.detach().cpu().numpy()\n",
    "            pred_train = pred_train.detach().cpu().numpy()\n",
    "            label_train = label_train.astype(\"int32\")\n",
    "            pred_train = pred_train.astype(\"int32\")\n",
    "            total_acc_train = accuracy_score(label_train, pred_train)\n",
    "#             print(total_acc_train)\n",
    "            total_f1_train = f1_score(label_train, pred_train, average='weighted')\n",
    "            total_loss_train = total_loss_train/(len(dataloader_train)*batch_size)\n",
    "            \n",
    "\n",
    "            \n",
    "            label_val =  torch.tensor([]).to(device)\n",
    "            pred_val = torch.tensor([]).to(device)\n",
    "            total_loss_val = 0\n",
    "\n",
    "            for val_input in dataloader_validation:\n",
    "                input_id = val_input[0].to(device)\n",
    "                mask = val_input[1].to(device)\n",
    "                val_label = val_input[2].to(device)\n",
    "                output = model(input_id, mask)\n",
    "                batch_loss = criterion(output, val_label)\n",
    "                total_loss_val += batch_loss.item()\n",
    "                label_val = torch.cat((label_val, val_label), 0)\n",
    "                pred_val = torch.cat((pred_val, output.argmax(dim=1)), 0)\n",
    "            \n",
    "            \n",
    "            label_val = label_val.detach().cpu().numpy()\n",
    "            pred_val = pred_val.detach().cpu().numpy()\n",
    "            label_val = label_val.astype(\"int32\")\n",
    "            pred_val = pred_val.astype(\"int32\")\n",
    "            total_acc_val = accuracy_score(label_val, pred_val)\n",
    "            total_f1_val = f1_score(label_val, pred_val, average='weighted')\n",
    "            total_loss_val = total_loss_val/(len(dataloader_validation)*batch_size)\n",
    "            \n",
    "            print('train_accuracy: ', total_acc_train, ', train_f1: ', total_f1_train, ', train_loss: ', total_loss_train)\n",
    "            print('val_accuracy: ', total_acc_val, ',  val_f1: ', total_f1_val, ', val_loss: ', total_loss_val)\n",
    "\n",
    "            torch.save(model.state_dict(), \n",
    "                       f'/mnt/bert_models/BERT_encoder{HIDDEN_LAYER}_attention{ATTENTION}_epoch{i}.model')\n",
    "\n",
    "            logs.append({'epoch': i,\n",
    "                     'train_accuracy': total_acc_train,\n",
    "                     'train_f1': total_f1_train,\n",
    "                     'train_loss': total_loss_train,\n",
    "                     'val_accuracy': total_acc_val,\n",
    "                     'val_f1': total_f1_val,\n",
    "                     'val_loss': total_loss_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff004a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.DataFrame(logs)\n",
    "log['val_loss'] = log['val_loss'].round(3)\n",
    "log['train_loss'] = log['train_loss'].round(3)\n",
    "log['train_f1'] = log['train_f1'].round(2)\n",
    "log['val_f1'] = log['val_f1'].round(2)\n",
    "#log.index = log.epoch\n",
    "#del log['epoch']\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(20,10))\n",
    "ax.grid(True)\n",
    "plt1 = ax.plot(log.epoch, log.train_f1, color=\"red\", label= 'train_f1')\n",
    "plt2 = ax.plot(log.epoch, log.val_f1, color=\"green\", label= 'val_f1')\n",
    "\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"iterations\", fontsize = 14)\n",
    "\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"F1\", fontsize=14)\n",
    "\n",
    "ax.set_xticks(log.epoch.values)\n",
    "\n",
    "ax2=ax.twinx()\n",
    "plt3 = ax2.plot(log.epoch, log.train_loss,color=\"red\", label='train_loss')\n",
    "plt4 = ax2.plot(log.epoch, log.val_loss,color=\"green\", label= 'val_loss')\n",
    "\n",
    "lns = plt1+plt2+plt3+plt4\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labs, loc='center right')\n",
    "\n",
    "ax2.set_ylabel(\"LOSS\", fontsize=14)\n",
    "plt.grid(color = 'green', linestyle = '--', linewidth = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee45ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "#plt.plot(log.epoch, log.train_accuracy, label= 'train_accuracy')\n",
    "plt.plot(log.epoch, log.train_f1, label= 'train_f1')\n",
    "#plt.plot(log.epoch, log.val_accuracy, label= 'val_accuracy')\n",
    "plt.plot(log.epoch, log.val_f1, label='val_f1')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xticks(log.epoch, rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68fc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(log.epoch, log.train_loss, label='train_loss')\n",
    "plt.plot(log.epoch, log.val_loss, label='val_loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xticks(log.epoch, rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381939f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''EPOCH = 5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8,\n",
    "                  no_deprecation_warning=True)\n",
    "                  \n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=500,\n",
    "                                            num_training_steps=len(dataloader_train)*EPOCH)\n",
    "\n",
    "logs = []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    print('epoch--- ',epoch+1)\n",
    "    total_loss_train = 0\n",
    "    label_train =  torch.tensor([], dtype=torch.uint8).to(device)\n",
    "    pred_train = torch.tensor([], dtype=torch.uint8).to(device)\n",
    "\n",
    "    for train_input in tqdm(dataloader_train):\n",
    "        model.zero_grad()\n",
    "        input_id = train_input[0].to(device)\n",
    "        mask = train_input[1].to(device)\n",
    "        train_label = train_input[2].to(device)\n",
    "        output = model(input_id, mask)\n",
    "        label_train = torch.cat((label_train, train_label), 0)\n",
    "        batch_loss = criterion(output, train_label)\n",
    "        total_loss_train += batch_loss.item()\n",
    "        pred_train = torch.cat((pred_train, output.argmax(dim=1)), 0)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        #break\n",
    "    \n",
    "    label_train = label_train.detach().cpu().numpy()\n",
    "    pred_train = pred_train.detach().cpu().numpy()\n",
    "    total_acc_train = accuracy_score(label_train, pred_train)\n",
    "    total_f1_train = f1_score(label_train, pred_train, average='weighted')\n",
    "    total_loss_train = total_loss_train/(len(dataloader_train)*batch_size)\n",
    "\n",
    "    label_val =  torch.tensor([], dtype=torch.uint8).to(device)\n",
    "    pred_val = torch.tensor([], dtype=torch.uint8).to(device)\n",
    "    total_loss_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_input in tqdm(dataloader_validation):\n",
    "            input_id = val_input[0].to(device)\n",
    "            mask = val_input[1].to(device)\n",
    "            val_label = val_input[2].to(device)\n",
    "            output = model(input_id, mask)\n",
    "            label_val = torch.cat((label_val, val_label), 0)\n",
    "            batch_loss = criterion(output, val_label)\n",
    "            total_loss_val += batch_loss.item()\n",
    "            pred_val = torch.cat((pred_val, output.argmax(dim=1)), 0)\n",
    "            #break\n",
    "    \n",
    "    label_val = label_val.detach().cpu().numpy()\n",
    "    pred_val = pred_val.detach().cpu().numpy()\n",
    "    total_acc_val = accuracy_score(label_val, pred_val)\n",
    "    total_f1_val = f1_score(label_val, pred_val, average='weighted')\n",
    "    total_loss_val = total_loss_val/(len(dataloader_validation)*batch_size)\n",
    "    \n",
    "    torch.save(model.state_dict(), f'./model/BERT_encoder{HIDDEN_LAYER}_attention{ATTENTION}_epoch{epoch+1}.model')\n",
    "    \n",
    "    print('train_accuracy: ', total_acc_train, ', train_f1: ', total_f1_train, ', train_loss: ', total_loss_train)\n",
    "    print('val_accuracy: ', total_acc_val, ',  val_f1: ', total_f1_val, ', val_loss: ', total_loss_val)\n",
    "    print('\\n')\n",
    "    \n",
    "    logs.append({'epoch': epoch+1,\n",
    "                 'train_accuracy': total_acc_train,\n",
    "                 'train_f1': total_f1_train,\n",
    "                 'train_loss': total_loss_train,\n",
    "                 'val_accuracy': total_acc_val,\n",
    "                 'val_f1': total_f1_val,\n",
    "                 'val_loss': total_loss_val})'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c38db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5acf13",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133860e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['label'] = df_test.new_category.replace(label_dict)\n",
    "#df_test = pd.read_csv(\"/data/mmortgage/amal_workspace/multipageAccuracy/data/processed/testing_domain_processed.csv\")\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a5ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e90ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[\"new_category\"] = \"others1\"\n",
    "# df_test[\"new_category\"].loc[df_test[\"Actual Classification\"] == \"Non-Mortgage Statement\"] = \"Non-Mortgage Statement\"\n",
    "# df_test[\"new_category\"].loc[df_test[\"Actual Classification\"] == \"Bank Statement\"] = \"Bank Statement\"\n",
    "# df_test[\"new_category\"].loc[df_test[\"Actual Classification\"] == \"Mortgage Statement\"] = \"Mortgage Statement\"\n",
    "# df_test[\"new_category\"].loc[df_test[\"Actual Classification\"] == \"Retirement Account Statement(s)\"] = \"Retirement Account Statement(s)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b08a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b4f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERTEncode(df, size, shuffle=False):\n",
    "    encoded_data = tokenizer.batch_encode_plus(\n",
    "        df.text_processed.values, \n",
    "        add_special_tokens=True, \n",
    "        return_attention_mask=True, \n",
    "        padding='max_length', \n",
    "        max_length=512, \n",
    "        truncation=True,\n",
    "        return_tensors='pt')\n",
    "    input_ids = encoded_data['input_ids']\n",
    "    attention_masks = encoded_data['attention_mask']\n",
    "    labels = torch.tensor(df.label.values)\n",
    "    tensordataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    dataloader = DataLoader(tensordataset,\n",
    "                            shuffle=shuffle,\n",
    "                            num_workers=0,\n",
    "                            batch_size=size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac214b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./bert-base-uncased-customizedtokens') # '../amal_workspace/multipageAccuracy/bert-base-uncased'\n",
    "dataloader_test = BERTEncode(test, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31c1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTENTION = 12\n",
    "HIDDEN_LAYER = 1\n",
    "CLASSES = len(label_dict)\n",
    "\n",
    "model = BertClassifier(dropout=0.2, \n",
    "                       BERTconfig=True, \n",
    "                       attention_heads=ATTENTION,\n",
    "                       hidden_layers=HIDDEN_LAYER,\n",
    "                       numclass= CLASSES,\n",
    "                       hidden_dropout_prob=0.1,\n",
    "                       position_embedding_type='absolute')\n",
    "#model = BertClassifier(BERTconfig=False, numclass= CLASSES)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"/mnt/bert_models/BERT_encoder1_attention12_epoch1750.model\", map_location=torch.device('cuda')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model):\n",
    "    actual =  torch.tensor([]).to(device)\n",
    "    predicted = torch.tensor([]).to(device)\n",
    "    cr = []\n",
    "\n",
    "    for input in tqdm(dataloader):\n",
    "        input_id = input[0].to(device)\n",
    "        mask = input[1].to(device)\n",
    "        labels = input[2].to(device)\n",
    "        actual = torch.cat((actual, labels), 0)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_id, mask)\n",
    "        predicted = torch.cat((predicted, output.argmax(dim=1)), 0)\n",
    "        for logits in output:\n",
    "            score = torch.nn.functional.softmax(logits, dim=0)\n",
    "            cr.append(np.float64(score.max(dim=0)[0].detach().cpu().numpy()))\n",
    "    \n",
    "    actual = actual.detach().cpu().numpy()\n",
    "    predicted = predicted.detach().cpu().numpy()\n",
    "    actual = actual.astype('int8')\n",
    "    predicted = predicted.astype('int8')\n",
    "    total_acc_test = accuracy_score(actual, predicted)\n",
    "    total_f1_test = f1_score(actual, predicted, average='weighted')\n",
    "    print('Test Accuracy:', round(total_acc_test,2))\n",
    "    print('Test f1:', round(total_f1_test,2))\n",
    "    return (actual, predicted, cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad92fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, predicted, cr =validate(dataloader_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b32c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict_inv=dict()\n",
    "for label in label_dict:\n",
    "    label_dict_inv[label_dict[label]]=label\n",
    "label_dict_inv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c448026",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkfor = range(len(label_dict))\n",
    "#checkfor = [0]\n",
    "final_predicted = []\n",
    "    \n",
    "classes = []\n",
    "for check in checkfor:\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    notclassified = 0\n",
    "    score = []\n",
    "    for a,p, c in zip(actual, predicted, cr):\n",
    "             \n",
    "        if a == check:\n",
    "            total+=1\n",
    "            if (p == check):\n",
    "                correct+=1\n",
    "            elif (p!=check):\n",
    "                notclassified+=1\n",
    "                score.append(c)\n",
    "                if(check==1):\n",
    "                    classes.append(p)\n",
    "                \n",
    "    if total!=0:\n",
    "        acc = round(correct/total,2)\n",
    "        print('accuracy for {}: {}/{}={}'.format(label_dict_inv[check],correct,total,acc))\n",
    "        print('notclassified {}'.format(notclassified))\n",
    "        if notclassified!=0:\n",
    "            print('notclassified score for {}'.format(np.median(score)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215151b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(classes, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0177b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b885c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cb75ec7",
   "metadata": {},
   "source": [
    "### GLOBAL_VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d270e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_validate = pd.read_csv('./global_validate.csv')\n",
    "global_validate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744cce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_validate = global_validate[global_validate['new_text_format']=='new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea29ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_validate.drop(global_validate[global_validate['category']=='Tax Return'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "index=[]\n",
    "for i,row in global_validate.iterrows():\n",
    "    if row['ADR'] in data['ADR'].values.tolist():\n",
    "        if row['text'] in data['text'][data['ADR']==row['ADR']].values.tolist():\n",
    "            count+=1\n",
    "            index.append(i)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6430ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del global_validate['new_category']\n",
    "#global_validate.drop(index=index, inplace=True)\n",
    "global_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c187e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_validate['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate.to_csv('./global_validate.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "# cats = ['Retirement Account Statement(s)',\n",
    "#         'Mortgage Statement',\n",
    "#         'Bank Statement',\n",
    "#         'Purchase Agreement',\n",
    "#         'Rental Agreements(s)',\n",
    "#         'Hazard Insurance',\n",
    "#         'Divorce Decree / Child Support',\n",
    "#         'Bankruptcy Papers']\n",
    "\n",
    "cats = ['Purchase Agreement',\n",
    "        'Rental Agreements(s)',\n",
    "        'Due Diligence Report']\n",
    "\n",
    "for category in global_validate['category']:\n",
    "    if category not in cats:\n",
    "        temp.append('others')\n",
    "    else:\n",
    "        temp.append(category)\n",
    "global_validate['new_category'] = temp\n",
    "global_validate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['label'] = global_validate.new_category.replace(label_dict)\n",
    "global_validate.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['text']= [str(text) for text in global_validate['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c423606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERTEncode(df, size, shuffle=False):\n",
    "    encoded_data = tokenizer.batch_encode_plus(\n",
    "        df['new_format_text'].values, \n",
    "        add_special_tokens=True, \n",
    "        return_attention_mask=True, \n",
    "        padding='max_length', \n",
    "        max_length=512, \n",
    "        truncation=True,\n",
    "        return_tensors='pt')\n",
    "    input_ids = encoded_data['input_ids']\n",
    "    attention_masks = encoded_data['attention_mask']\n",
    "    labels = torch.tensor(df.label.values)\n",
    "    tensordataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    dataloader = DataLoader(tensordataset,\n",
    "                            shuffle=shuffle,\n",
    "                            num_workers=0,\n",
    "                            batch_size=size)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c202ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = BERTEncode(global_validate, 32, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47de2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dc2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTENTION = 12\n",
    "HIDDEN_LAYER = 1\n",
    "CLASSES = len(label_dict)\n",
    "\n",
    "\n",
    "model = BertClassifier(dropout=0.2, \n",
    "                       BERTconfig=True, \n",
    "                       attention_heads=ATTENTION,\n",
    "                       hidden_layers=HIDDEN_LAYER,\n",
    "                       numclass= CLASSES,\n",
    "                       hidden_dropout_prob=0.1,\n",
    "                       position_embedding_type='absolute')\n",
    "\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('/mnt/bert_models/BERT_encoder1_attention12_epoch5250.model', map_location=torch.device('cuda')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68830f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, predicted, cr = validate(dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f5d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict_inv=dict()\n",
    "for label in label_dict:\n",
    "    label_dict_inv[label_dict[label]]=label\n",
    "label_dict_inv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd5da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6901f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshholds = range(0,92,2)\n",
    "checkfor = range(len(label_dict))\n",
    "\n",
    "accuracy=[]\n",
    "notclassified = []\n",
    "for thresh in threshholds:\n",
    "    \n",
    "    final_predicted=[]\n",
    "    for a,p,c in zip(actual, predicted, cr):\n",
    "        if c>(thresh/100):\n",
    "            final_predicted.append(p)\n",
    "        else:\n",
    "            final_predicted.append(0)\n",
    "    \n",
    "    acc = 0\n",
    "    incorrect = 0\n",
    "    for check in checkfor:\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for a,p,c in zip(actual, final_predicted, cr):\n",
    "            if a == check:\n",
    "                total+=1\n",
    "                if (p == check):\n",
    "                    correct+=1\n",
    "                elif (p!=check):\n",
    "                    incorrect+=1\n",
    "        if(total!=0):\n",
    "            acc = acc+round(correct/total,2)\n",
    "    #accuracy.append(acc/len(checkfor))\n",
    "    accuracy.append(acc/len(global_validate['new_category'].unique()))\n",
    "    notclassified.append(incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "ax.plot(threshholds,\n",
    "        accuracy,\n",
    "        color=\"red\", \n",
    "        marker=\"o\")\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"threshold\", fontsize = 14)\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"accuracy\",\n",
    "              color=\"red\",\n",
    "              fontsize=14)\n",
    "\n",
    "ax.set_xticks(list(threshholds))\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(threshholds, notclassified,color=\"blue\",marker=\"o\")\n",
    "ax2.set_ylabel(\"notclassified\",color=\"blue\",fontsize=14)\n",
    "plt.grid(color = 'green', linestyle = '--', linewidth = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc87cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkfor = range(len(label_dict))\n",
    "#checkfor = [0]\n",
    "final_predicted = []\n",
    "\n",
    "for a,p, c in zip(actual, predicted, cr):\n",
    "    if c>0.90:\n",
    "        final_predicted.append(p)\n",
    "    else:\n",
    "        final_predicted.append(0)\n",
    "    \n",
    "\n",
    "for check in checkfor:\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    notclassified = 0\n",
    "    score = []\n",
    "    for a,p, c in zip(actual, final_predicted, cr):\n",
    "             \n",
    "        if a == check:\n",
    "            total+=1\n",
    "            if (p == check):\n",
    "                correct+=1\n",
    "            #elif ((p!=check)&(c<0.90)):\n",
    "            #    correct+=1\n",
    "            #elif ((p!=check)&(c>0.90)):\n",
    "            #    notclassified+=1\n",
    "            elif (p!=check):\n",
    "                notclassified+=1\n",
    "                score.append(c)\n",
    "                \n",
    "    if total!=0:\n",
    "        acc = round(correct/total,2)\n",
    "        print('accuracy for {}: {}/{}={}'.format(label_dict_inv[check],correct,total,acc))\n",
    "        print('notclassified {}'.format(notclassified))\n",
    "        if notclassified!=0:\n",
    "            print('notclassified score for {}'.format(np.median(score)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['predlabel'] = list(final_predicted)\n",
    "global_validate['predicted'] = [label_dict_inv[i] for i in final_predicted]\n",
    "global_validate['cr'] = list(cr)\n",
    "#global_validate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['category'][(global_validate['new_category']=='others')&\n",
    "                            (global_validate['predicted']!='others')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1fdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca68654",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate[(global_validate['label']==0)&(global_validate['predlabel']!=0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c67c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e310f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da9f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f066eab",
   "metadata": {},
   "source": [
    "### after deployment validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_validate = pd.read_csv('/data/mmortgage/amal_workspace/multi_page_classification_preprocessing/domain_testing/BERT Testing_10.08.2022_Results.csv')\n",
    "global_validate = pd.read_csv('./test.csv')\n",
    "global_validate.head(1)\n",
    "global_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c5797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count=0\n",
    "# index=[]\n",
    "# for i,adr in enumerate(global_validate['ADR']):\n",
    "#     if adr in data['ADR'].values.tolist():\n",
    "#         count+=1\n",
    "#         index.append(i)\n",
    "# global_validate.drop(index=index, inplace=True)\n",
    "global_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e507c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['Actual Classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce20211",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = {\n",
    "    'others': 0,\n",
    " 'Retirement Account Statement(s)': 1,\n",
    " 'Mortgage Statement': 2,\n",
    " 'Bank Statement': 3,\n",
    " 'Non-Mortgage Statement': 4,\n",
    " 'Due Diligence Report': 5,\n",
    " 'Purchase Agreement': 6,\n",
    " 'Rental Agreements(s)': 7,\n",
    " 'Hazard Insurance': 8,\n",
    " 'Divorce Decree / Child Support': 9,\n",
    " 'Bankruptcy Papers': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_inv=dict()\n",
    "for lab in label:\n",
    "    label_inv[label[lab]]=lab\n",
    "label_inv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14baaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "\n",
    "cats = list(label.keys())\n",
    "\n",
    "for category in global_validate['Actual Classification']:\n",
    "    if category not in cats:\n",
    "        temp.append('others')\n",
    "    else:\n",
    "        temp.append(category)\n",
    "global_validate['new_category'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc6335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['label'] = global_validate.new_category.replace(label)\n",
    "global_validate.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['new_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b316478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49379949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 dropout=0.1, \n",
    "                 BERTconfig=False, \n",
    "                 attention_heads=12, \n",
    "                 hidden_layers=12, \n",
    "                 numclass=1,\n",
    "                 hidden_dropout_prob=0.1,\n",
    "                 hidden_act='gelu',\n",
    "                 position_embedding_type='absolute'):\n",
    "        \n",
    "        #self.attention_heads = attention_heads\n",
    "        super(BertClassifier, self).__init__()\n",
    "        \n",
    "        if BERTconfig:\n",
    "            configuration = BertConfig(num_attention_heads= attention_heads, \n",
    "                                       num_hidden_layers= hidden_layers)   \n",
    "        else:\n",
    "            configuration = BertConfig()\n",
    "        #self.bert = BertModel.from_pretrained('bert-base-uncased', output_attentions=attention)\n",
    "        #print(configuration)\n",
    "        self.bert = BertModel(configuration)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, numclass, bias=True)\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c753bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import ast\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "configs = configparser.ConfigParser()\n",
    "configs.read('./config.ini')\n",
    "labels = []\n",
    "BERT_MODELS = []\n",
    "THRESHOLDS=[]\n",
    "GARBAGE_REMOVAL=[]\n",
    "\n",
    "for config in configs.sections():\n",
    "    label_ = ast.literal_eval(configs[config].get('categoryMAP'))\n",
    "    labels.append(label_)\n",
    "    THRESHOLDS.append(float(configs[config].get('cr_thresh')))\n",
    "    GARBAGE_REMOVAL.append(bool(configs[config].get('garbageremoval')))\n",
    "    HIDDEN_LAYERS = int(configs[config].get('hidden_layers'))\n",
    "    ATTENTIONS = int(configs[config].get('attentions'))\n",
    "    CLASSES = len(label_)\n",
    "    MODEL_FOLDER = configs[config].get('modelfolder')\n",
    "    model = BertClassifier(BERTconfig=True, \n",
    "                           attention_heads=ATTENTIONS, \n",
    "                           hidden_layers=HIDDEN_LAYERS, \n",
    "                           numclass= CLASSES)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load('./model/{}/BERT.model'.format(MODEL_FOLDER), map_location=torch.device('cuda')))\n",
    "    model.eval()\n",
    "    BERT_MODELS.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c82a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_words = set(stopwords.words('english') + list(string.punctuation))\n",
    "def predict(model, text, labels, thresh, grabageremoval):\n",
    "    \n",
    "    if grabageremoval:\n",
    "        text = re.sub(r'[~^0-9]', '', str(text))\n",
    "        wordlist = [word for word in word_tokenize(text.lower()) if not word in remove_words]\n",
    "        text = (\" \").join(wordlist)\n",
    "    \n",
    "    encoded_data = tokenizer.encode_plus(\n",
    "            str(text), \n",
    "            add_special_tokens=True, \n",
    "            return_attention_mask=True, \n",
    "            padding='max_length', \n",
    "            max_length=512, \n",
    "            truncation=True,\n",
    "            return_tensors='pt')\n",
    "    \n",
    "    input_ids_text = encoded_data['input_ids'].to(device)\n",
    "    attention_masks_text = encoded_data['attention_mask'].to(device)\n",
    "\n",
    "    with  torch.no_grad(): \n",
    "        outputs = model(input_ids_text, attention_masks_text)\n",
    "        \n",
    "    scores = torch.nn.functional.softmax(outputs.detach().cpu(), dim=1).numpy()[0]\n",
    "    \n",
    "    if np.max(scores)>thresh:\n",
    "        return (labels[np.argmax(scores)],np.max(scores))\n",
    "    else:\n",
    "        return ('others', np.max(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fee5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = ['LibertyGuard Deluxe Homeowner Policy Declarations Liberty Mutual Personal Insurance Company Liberty Mutual. INSURANCE FAX: ATTN: POLICY NUMBER: H3V-251-492955-70 NAME & ADDRESS Charles Corbett Dolores McKeehan 403 Poplar Ridge Rd Chapmansboro, TN 37035-5334 RESIDENCE PREMISES INSURED 4127 Meadow View Cir Pleasant View, TN 37146-8198 THESE DECLARATIONS EFFECTIVE 12/21/2021 Same as Residence POLICY PERIOD 12/21/2021 through 12/21/2022 RESIDENCE PREMISES 403 Poplar Ridge Rd Chapmmsboro, TN 37035-5334 SECTIONI AND II: COVERAGES AND LIMITS UNDER YOUR LIBERTY GUARD HOMEOWNERS POLICY I: COVERAGE A - YOUR DWELLING COVERAGE B - OTHER STRUCTURES ON RESIDENCE PREMISES COVERAGE C - PERSONAL PROPERTY COVERAGE D - LOSS OF USE OF YOUR RESIDENCE PREMISES $ 280,500 $ 28,050 $ 210,380 Actual Loss Sustained II: COVERAGE E - PERSONAL LIABILITY (EACH OCCURRENCE) COVERAGE F - MEDICAL PAYMENTS TO OTHERS (EACH PERSON) $ 300,000 5,000 DEDUCTIBLE: LOSSES COVERED UNDER SECTION I ARE SUBJECT TO A DEDUCTIBLE OF 1% Wind/Hail (if applicable) 1% NET PREMIUM: $1,359.00 PAID IN FULL NO Replacement Cost Coverage X Yes No Expanded Replacement Cost [X] 20% No Functional Replacement Roof Replacement Cost Coverage Yes [X] No Mortgagee 1 HIGHLANDS RESIDENTIAL MORTGAGE, LTD. Loan # 7018195910 Issoe/atime C/O Conlar P.O. Box 202028 Florence, SC 29502 Jans mathe Market President Secretary Countersigned by: Date: December 09, 2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "pred_label = []\n",
    "i=0\n",
    "for txt in global_validate['text'].values:\n",
    "#for txt in txts:\n",
    "#for txt in zip(global_validate['text'].values, global_validate['Ref. No.'].values, global_validate['text'].values:\n",
    "    i=i+1\n",
    "    print(i)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        predictions = executor.map(predict, \n",
    "                                   BERT_MODELS, \n",
    "                                   [txt]*len(labels), \n",
    "                                   labels, \n",
    "                                   THRESHOLDS,\n",
    "                                   GARBAGE_REMOVAL)\n",
    "    predictions = list(predictions)\n",
    "    print(predictions)\n",
    "\n",
    "    if(predictions[0][0]=='focused'):\n",
    "        classifications = list(filter(lambda x: x[0]!='others', predictions[1:]))\n",
    "        if len(classifications)==0:\n",
    "            final_class = sorted(predictions[1:],key=lambda x: x[1], reverse=True)[0]\n",
    "        else:\n",
    "            final_class = sorted(classifications,key=lambda x: x[1], reverse=True)[0]\n",
    "\n",
    "        '''if final_class[1]>0.90:\n",
    "            final_class = final_class\n",
    "        else:\n",
    "            final_class = ('others',final_class[1])'''\n",
    "    else:\n",
    "        final_class = ('others',predictions[0][1])\n",
    "        \n",
    "    pred_label.append(label[final_class[0]])\n",
    "    print(final_class)\n",
    "    print('\\n')\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32466001",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(global_validate['label'].values, np.array(pred_label))\n",
    "f1 = f1_score(global_validate['label'].values, np.array(pred_label), average='weighted')\n",
    "acc,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b0d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cadc621",
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(label_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkfor = range(len(label_inv))\n",
    "for check in checkfor:\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    notclassified = 0\n",
    "    score = []\n",
    "    for a,p in zip(global_validate['label'].values, np.array(pred_label)):\n",
    "             \n",
    "        if a == check:\n",
    "            total+=1\n",
    "            if (p == check):\n",
    "                correct+=1\n",
    "            elif (p!=check):\n",
    "                notclassified+=1\n",
    "                \n",
    "    if total!=0:\n",
    "        acc = round(correct/total,2)\n",
    "        print('accuracy for {}: {}/{}={}'.format(label_inv[check],correct,total,acc))\n",
    "        #print('notclassified {}'.format(notclassified))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17972034",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['pred_label'] = pred_label\n",
    "global_validate.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['pred_category'] = global_validate['pred_label'].replace(label_inv )\n",
    "global_validate.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7f7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate['new_category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43795201",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i,j in zip(global_validate['new_category'].values, global_validate['pred_category'].values):\n",
    "    if i==j:\n",
    "        temp.append('PASS')\n",
    "    else:\n",
    "        temp.append('FAIL')\n",
    "global_validate['local_P/F']= temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e1298",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate.to_csv('./valid.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb837451",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_validate[(global_validate['label']==0)&\n",
    "                            (global_validate['pred_label']!=0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea93914",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank \n",
    "morgage \n",
    "Retirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Purchase\n",
    "Rental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8705aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax return\n",
    "k1\n",
    "w2\n",
    "paystub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1747b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147fadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.char as nac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257eade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "augc= nac.OcrAug() \n",
    "'''aug = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', \n",
    "                                model_type='bert',\n",
    "                                action=\"insert\", \n",
    "                                aug_p=0.80)'''\n",
    "                                \n",
    "#augs = nas.ContextualWordEmbsForSentenceAug(model_path='gpt2', top_p=0.5, batch_size=4)\n",
    "#randomSentAug = nas.random.RandomSentAug(mode='neighbor', action='swap') <---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e213ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [data['text'][1],data['text'][0]]\n",
    "augmented_data = augc.augment(txt)\n",
    "#augmented_data = randomWordAug.augment(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff0dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec9720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c8d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f1f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification_service",
   "language": "python",
   "name": "classification_service"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
